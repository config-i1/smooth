{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# M-Competition Evaluation\n",
    "\n",
    "This notebook evaluates ADAM and ES models on M1 and M3 competition datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import multiprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from mcomp import M1, M3, load_m1, load_m3\n",
    "from smooth import ADAM, ES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error-metrics-header",
   "metadata": {},
   "source": [
    "## Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "error-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSSE(holdout, forecast, actuals):\n",
    "    \"\"\"\n",
    "    Root Mean Squared Scaled Error.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    holdout : array-like\n",
    "        Actual holdout values\n",
    "    forecast : array-like\n",
    "        Forecasted values\n",
    "    actuals : array-like\n",
    "        In-sample actual values (for scaling)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        RMSSE value\n",
    "    \"\"\"\n",
    "    holdout = np.asarray(holdout)\n",
    "    forecast = np.asarray(forecast)\n",
    "    actuals = np.asarray(actuals)\n",
    "    \n",
    "    mse = np.mean((holdout - forecast) ** 2)\n",
    "    scale = np.mean(np.diff(actuals) ** 2)\n",
    "    \n",
    "    if scale == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return np.sqrt(mse / scale)\n",
    "\n",
    "def SAME(holdout, forecast, actuals):\n",
    "    \"\"\"\n",
    "    Scaled Absolute Mean Error.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    holdout : array-like\n",
    "        Actual holdout values\n",
    "    forecast : array-like\n",
    "        Forecasted values\n",
    "    actuals : array-like\n",
    "        In-sample actual values (for scaling)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        RMSSE value\n",
    "    \"\"\"\n",
    "    holdout = np.asarray(holdout)\n",
    "    forecast = np.asarray(forecast)\n",
    "    actuals = np.asarray(actuals)\n",
    "    \n",
    "    ame = np.abs(np.mean(holdout - forecast))\n",
    "    scale = np.mean(np.abs(np.diff(actuals)))\n",
    "    \n",
    "    if scale == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return ame / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-header",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded M1 dataset: 1001 series\n",
      "Loaded M3 dataset: 3003 series\n",
      "Total series: 4004\n",
      "M1: 1001 series\n",
      "M3: 3003 series\n"
     ]
    }
   ],
   "source": [
    "# Load M1 and M3 datasets\n",
    "m1 = load_m1()\n",
    "m3 = load_m3()\n",
    "\n",
    "# Combine datasets into a list\n",
    "datasets = []\n",
    "for idx in m1.keys():\n",
    "    datasets.append(m1[idx])\n",
    "for idx in m3.keys():\n",
    "    datasets.append(m3[idx])\n",
    "\n",
    "print(f\"Total series: {len(datasets)}\")\n",
    "print(f\"M1: {len(m1)} series\")\n",
    "print(f\"M3: {len(m3)} series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "methods-header",
   "metadata": {},
   "source": [
    "## Define Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "methods-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods: 6\n",
      "Datasets: 4004\n"
     ]
    }
   ],
   "source": [
    "# Method names\n",
    "methods_names = [\n",
    "    \"ADAM ETS Back\",\n",
    "    \"ADAM ETS Opt\", \n",
    "    \"ADAM ETS Two\",\n",
    "    \"ES Back\",\n",
    "    \"ES Opt\",\n",
    "    \"ES Two\"\n",
    "]\n",
    "\n",
    "methods_number = len(methods_names)\n",
    "dataset_length = len(datasets)\n",
    "\n",
    "print(f\"Methods: {methods_number}\")\n",
    "print(f\"Datasets: {dataset_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf4b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y': array([5.13, 5.16, 5.17, 5.2 , 5.22, 5.2 , 5.24, 5.26, 5.27, 5.3 , 5.32,\n",
      "       5.34, 5.39, 5.43, 5.45, 5.49, 5.54, 5.57, 5.59, 5.59, 5.58, 5.54,\n",
      "       5.53, 5.54, 5.54, 5.56, 5.6 , 5.6 , 5.6 , 5.59, 5.57, 5.53, 5.5 ,\n",
      "       5.48, 5.44, 5.45, 5.49, 5.54, 5.58, 5.63, 5.68, 5.69, 5.71, 5.72,\n",
      "       5.73, 5.74, 5.77, 5.79, 5.78, 5.78, 5.81, 5.83, 5.86, 5.9 , 5.91,\n",
      "       5.94]), 'states': array([[5.14237701,        nan],\n",
      "       [5.16041345, 0.01803643],\n",
      "       [5.17838693, 0.01797348],\n",
      "       [5.19629263, 0.0179057 ],\n",
      "       [5.21412598, 0.01783334],\n",
      "       [5.23188201, 0.01775603],\n",
      "       [5.24955565, 0.01767364],\n",
      "       [5.26714384, 0.01758819],\n",
      "       [5.28464532, 0.01750148],\n",
      "       [5.30206087, 0.01741555],\n",
      "       [5.31939437, 0.0173335 ],\n",
      "       [5.3366533 , 0.01725893],\n",
      "       [5.3538501 , 0.0171968 ],\n",
      "       [5.37100413, 0.01715404],\n",
      "       [5.38814298, 0.01713885],\n",
      "       [5.40530655, 0.01716356],\n",
      "       [5.42255315, 0.0172466 ],\n",
      "       [5.43995309, 0.01739994],\n",
      "       [5.45752449, 0.0175714 ],\n",
      "       [5.47317465, 0.01565016],\n",
      "       [5.48860811, 0.01543347],\n",
      "       [5.5037109 , 0.01510278],\n",
      "       [5.51827428, 0.01456339],\n",
      "       [5.53196729, 0.013693  ],\n",
      "       [5.54440291, 0.01243563],\n",
      "       [5.555266  , 0.01086309],\n",
      "       [5.56462066, 0.00935466],\n",
      "       [5.57304318, 0.00842252],\n",
      "       [5.58120222, 0.00815903],\n",
      "       [5.58945928, 0.00825706],\n",
      "       [5.59795148, 0.00849221],\n",
      "       [5.6067166 , 0.00876512],\n",
      "       [5.61571831, 0.00900171],\n",
      "       [5.62488759, 0.00916928],\n",
      "       [5.63416661, 0.00927902],\n",
      "       [5.64352085, 0.00935424],\n",
      "       [5.65293284, 0.00941198],\n",
      "       [5.66238396, 0.00945112],\n",
      "       [5.67365313, 0.01126917],\n",
      "       [5.68524607, 0.01159294],\n",
      "       [5.69701052, 0.01176444],\n",
      "       [5.70891646, 0.01190594],\n",
      "       [5.72096908, 0.01205262],\n",
      "       [5.73317354, 0.01220446],\n",
      "       [5.74553039, 0.01235685],\n",
      "       [5.7580378 , 0.01250741],\n",
      "       [5.77069357, 0.01265578],\n",
      "       [5.78349585, 0.01280228],\n",
      "       [5.79644235, 0.0129465 ],\n",
      "       [5.80953048, 0.01308813],\n",
      "       [5.82275903, 0.01322856],\n",
      "       [5.83612882, 0.01336978],\n",
      "       [5.84964166, 0.01351284],\n",
      "       [5.86329954, 0.01365788],\n",
      "       [5.87710301, 0.01380347],\n",
      "       [5.89104944, 0.01394643]]), 'initial': {'nonseasonal': {'level': np.float64(5.128764788648649), 'trend': np.float64(0.01361222598569663)}, 'seasonal': []}, 'seasonal': None, 'fitted': array([5.14237701, 5.16041345, 5.17838693, 5.19629263, 5.21412598,\n",
      "       5.23188201, 5.24955565, 5.26714384, 5.28464532, 5.30206087,\n",
      "       5.31939437, 5.3366533 , 5.3538501 , 5.37100413, 5.38814298,\n",
      "       5.40530655, 5.42255315, 5.43995309, 5.45752449, 5.47317465,\n",
      "       5.48860811, 5.5037109 , 5.51827428, 5.53196729, 5.54440291,\n",
      "       5.555266  , 5.56462066, 5.57304318, 5.58120222, 5.58945928,\n",
      "       5.59795148, 5.6067166 , 5.61571831, 5.62488759, 5.63416661,\n",
      "       5.64352085, 5.65293284, 5.66238396, 5.67365313, 5.68524607,\n",
      "       5.69701052, 5.70891646, 5.72096908, 5.73317354, 5.74553039,\n",
      "       5.7580378 , 5.77069357, 5.78349585, 5.79644235, 5.80953048,\n",
      "       5.82275903, 5.83612882, 5.84964166, 5.86329954, 5.87710301,\n",
      "       5.89104944]), 'gta': array([5.16945053, 0.01284305]), 'gtm': array([5.18896918, 1.0023271 ]), 'loss': 'MSE', 'lags': array([1]), 'type': 'additive', 'yName': 'y', 'smoother': 'lowess'}\n",
      "[0.1        0.05       0.95       5.12876479 0.01361223]\n",
      "-62.08156180281837\n",
      "[0.175      0.05       0.95       5.12876479 0.01361223]\n",
      "-74.52331738867858\n",
      "[0.175      0.0875     0.95       5.12876479 0.01361223]\n",
      "-78.10820271526472\n",
      "[0.175      0.0875     0.9875     5.12876479 0.01361223]\n",
      "-74.72009141396853\n",
      "[ 0.175       0.0875      0.95       10.25752958  0.01361223]\n",
      "85.30740185340221\n",
      "[0.175      0.0875     0.95       5.12876479 0.02722445]\n",
      "-77.27704112608882\n",
      "[0.145      0.0575     0.965      0.         0.01905712]\n",
      "89.65588439250064\n",
      "[0.1675     0.08       0.95375    7.69314718 0.01497345]\n",
      "48.34867161081469\n",
      "[0.1525     0.065      0.96125    2.56438239 0.01769589]\n",
      "49.20525635737861\n",
      "[0.16375    0.07625    0.955625   6.41095599 0.01565406]\n",
      "11.927378917532053\n",
      "[0.15625    0.06875    0.959375   3.84657359 0.01701528]\n",
      "9.85833700751595\n",
      "[0.158125   0.070625   0.9584375  4.48766919 0.01667498]\n",
      "-26.98734798343677\n",
      "[0.161875   0.074375   0.9565625  5.76986039 0.01599437]\n",
      "-21.717206755426297\n",
      "[0.1590625  0.0715625  0.95796875 4.80821699 0.01650482]\n",
      "-55.8826213776882\n",
      "[0.1609375  0.0734375  0.95703125 5.44931259 0.01616452]\n",
      "-48.25563763876595\n",
      "[0.15953125 0.07203125 0.95773438 4.96849089 0.01641975]\n",
      "-70.57207558885763\n",
      "[0.2438125  0.1038125  0.96809375 5.06465523 0.02018013]\n",
      "-82.87569041655856\n",
      "[0.31571875 0.13071875 0.97714063 5.03260045 0.02346407]\n",
      "-87.02252788332922\n",
      "[0.24675625 0.10525625 0.96812188 5.25057295 0.02019033]\n",
      "-77.76792353272816\n",
      "[0.25999    0.14939    0.983105   5.13902232 0.0256291 ]\n",
      "-82.13415805868331\n",
      "[0.293986   0.136646   0.943847   5.14312533 0.03043585]\n",
      "-89.25238787758639\n",
      "[0.353479   0.161219   0.9220205  5.1503056  0.03884766]\n",
      "-95.94317641006751\n",
      "[0.3653776  0.1661336  0.9701552  5.15174165 0.02147291]\n",
      "-95.03096742562421\n",
      "[0.34106989 0.17272829 0.95284666 4.99040097 0.02902005]\n",
      "-88.30246269605011\n",
      "[0.4792541  0.22457586 0.97210719 5.05686361 0.04176129]\n",
      "-105.68038190205355\n",
      "[0.63138114 0.29311378 0.98316079 5.02091302 0.05583582]\n",
      "-114.86191070253633\n",
      "[0.54282055 0.22017537 0.93902451 4.99936236 0.04182711]\n",
      "-107.83127657772455\n",
      "[0.57793253 0.27462927 0.92974244 5.09248899 0.05133734]\n",
      "-118.23025738709305\n",
      "[0.70903941 0.34658453 0.90604334 5.12243327 0.06527398]\n",
      "-126.31534989226616\n",
      "[0.69976919 0.30216222 0.93531508 5.18750139 0.06028294]\n",
      "-117.38522702999364\n",
      "[0.80921812 0.36316836 0.90407049 5.0404646  0.0833541 ]\n",
      "-129.027964022331\n",
      "[1.         0.46168574 0.87102813 4.98482607 0.11429469]\n",
      "-128.78736712215107\n",
      "[1.         0.4488627  0.94502518 4.99796425 0.08378192]\n",
      "-128.06768904301398\n",
      "[0.9969426  0.48138127 0.93042144 5.14834825 0.09758439]\n",
      "-126.93848029132964\n",
      "[1.         0.48374985 0.86518942 5.17777168 0.10027511]\n",
      "-122.83930825066074\n",
      "[1.         0.54733646 0.88498487 5.00729143 0.11182486]\n",
      "-132.24563438826212\n",
      "[1.         0.66992358 0.85981976 4.91718646 0.13759582]\n",
      "-117.88190965673525\n",
      "[0.80608005 0.39118348 0.9630287  4.94882904 0.07645259]\n",
      "-115.17000642974179\n",
      "[0.95152001 0.46060826 0.88964924 5.12053602 0.09431948]\n",
      "-131.85435037707578\n",
      "[1.         0.5739583  0.91561715 5.00340856 0.12307192]\n",
      "-130.48951004319187\n",
      "[0.90735266 0.47619236 0.88531733 4.9195177  0.10095651]\n",
      "-115.94164124534359\n",
      "[0.97454511 0.48008404 0.91914541 5.09114061 0.09842742]\n",
      "-133.71729451660664\n",
      "[0.8941133  0.52119946 0.86036168 5.10717224 0.12061719]\n",
      "-130.41101338731048\n",
      "[1.         0.67010625 0.88383286 5.09135495 0.13595025]\n",
      "-131.94859343109516\n",
      "[1.         0.57163786 0.93693013 5.01832039 0.10482038]\n",
      "-132.0617723087865\n",
      "[0.97042605 0.51795085 0.89019986 5.1280488  0.09506504]\n",
      "-131.72699884314187\n",
      "[0.97781954 0.53195271 0.89655418 5.09688874 0.10206676]\n",
      "-134.37394189301898\n",
      "[1.         0.65983867 0.91892974 5.00146243 0.12691639]\n",
      "-130.6242532341446\n",
      "[0.97099647 0.51041586 0.89696937 5.09076762 0.10246871]\n",
      "-134.39159816500967\n",
      "[0.96934445 0.38646453 0.93000073 5.03040858 0.071893  ]\n",
      "-131.91692372583557\n",
      "[0.99233611 0.59919582 0.89537482 5.07611835 0.11993594]\n",
      "-134.46803241130817\n",
      "[0.96627889 0.4959561  0.86028133 5.12656231 0.10906909]\n",
      "-130.21665577861862\n",
      "[0.99156972 0.55271742 0.91776793 5.04538087 0.10588256]\n",
      "-134.7146281830203\n",
      "[0.96290678 0.52240988 0.92533982 5.15282705 0.09968769]\n",
      "-126.10585100179928\n",
      "[0.9907267  0.54110482 0.89507361 5.04367534 0.10879057]\n",
      "-135.09221888698184\n",
      "[0.9948343  0.61407061 0.88155055 5.04999176 0.11723039]\n",
      "-135.96046000066752\n",
      "[1.         0.68106389 0.86275312 5.02941733 0.12663187]\n",
      "-135.60726847920233\n",
      "[0.99836579 0.5950491  0.89814033 5.02548484 0.1196565 ]\n",
      "-133.8048308528782\n",
      "[0.9829561  0.54772681 0.89695072 5.07903777 0.10646419]\n",
      "-135.24583963445883\n",
      "[1.         0.63151033 0.89771768 5.02691401 0.12085275]\n",
      "-134.20753316876178\n",
      "[0.98074053 0.54068948 0.89715645 5.07480422 0.10706472]\n",
      "-135.21813921894457\n",
      "[0.98399483 0.51932783 0.90002487 5.04103763 0.09823703]\n",
      "-135.10047819650265\n",
      "[0.98173126 0.5524504  0.87053455 5.07003781 0.1092322 ]\n",
      "-136.12562538087076\n",
      "[0.97681203 0.55231689 0.84691786 5.08236628 0.11090702]\n",
      "-135.9347057197051\n",
      "[0.97897611 0.56860123 0.88341325 5.08228834 0.10650085]\n",
      "-135.71336473413425\n",
      "[0.98370049 0.61008758 0.87181733 5.10142633 0.12035991]\n",
      "-132.9317714206832\n",
      "[0.98392124 0.54201777 0.89297299 5.0561348  0.10376775]\n",
      "-135.904698021559\n",
      "[0.98822708 0.58925725 0.87301237 5.06019197 0.11021343]\n",
      "-136.60569404420494\n",
      "[0.99197035 0.61354114 0.86094034 5.05288585 0.11178779]\n",
      "-137.02155519788585\n",
      "[0.98961721 0.60854565 0.85881395 5.04549766 0.1129434 ]\n",
      "-136.72146456292674\n",
      "[0.99785364 0.60364899 0.8625117  5.02753081 0.11548377]\n",
      "-135.42595685869114\n",
      "[0.98369549 0.57736317 0.87818786 5.06859896 0.10874658]\n",
      "-136.31670232831067\n",
      "[0.9928182  0.64437062 0.84703791 5.05867001 0.12020839]\n",
      "-137.01235531393763\n",
      "[0.98109871 0.58443778 0.84465529 5.06828435 0.10793696]\n",
      "-137.30912795486609\n",
      "[0.97423091 0.56962137 0.82620767 5.07743065 0.10329024]\n",
      "-137.5452250238437\n",
      "[0.99120161 0.65292638 0.83794054 5.05119544 0.11355836]\n",
      "-137.72875800366722\n",
      "[0.99593678 0.70316437 0.82164354 5.04177425 0.11572143]\n",
      "-137.92216643592835\n",
      "[0.99413389 0.67833409 0.8076695  5.04190441 0.11683393]\n",
      "-138.00491689625932\n",
      "[0.99935309 0.72881954 0.77241032 5.02855714 0.1208776 ]\n",
      "-137.75919802113424\n",
      "[0.99001884 0.67506698 0.80658563 5.06356841 0.11419332]\n",
      "-138.46628701294162\n",
      "[0.99021966 0.70832765 0.78047147 5.07260378 0.11481828]\n",
      "-138.72152214053204\n",
      "[0.98577843 0.66482483 0.7917351  5.05596957 0.10477228]\n",
      "-139.02506389033925\n",
      "[0.98225855 0.67505193 0.76408369 5.05461935 0.09705422]\n",
      "-139.371809499532\n",
      "[0.98274156 0.72025863 0.73909001 5.06244713 0.10729945]\n",
      "-139.63795244701757\n",
      "[0.97812716 0.77361737 0.67816485 5.06722777 0.10505527]\n",
      "-139.8208935619085\n",
      "[1.         0.84577679 0.71460556 5.03382117 0.11650301]\n",
      "-138.75481123971238\n",
      "[0.98195892 0.76927876 0.67635449 5.06629634 0.10438445]\n",
      "-139.81595616512553\n",
      "[0.97889182 0.83048692 0.63780252 5.07592296 0.09829217]\n",
      "-139.81997475215275\n",
      "[0.97827492 0.84935706 0.60793297 5.04655125 0.09369737]\n",
      "-138.30945988939789\n",
      "[0.98723348 0.743585   0.73733685 5.06609065 0.10953805]\n",
      "-139.69389036108998\n",
      "[0.96338797 0.6710312  0.6828914  5.09824165 0.08922665]\n",
      "-138.43368543186727\n",
      "[0.99084699 0.8020904  0.70667702 5.04992629 0.10968392]\n",
      "-139.68304978562517\n",
      "[0.9845648  0.89257144 0.6104506  5.07556626 0.11372733]\n",
      "-139.57003670140267\n",
      "[0.98398824 0.83819157 0.64885887 5.07032953 0.10955905]\n",
      "-139.85444980723258\n",
      "[0.97323286 0.77997345 0.64473001 5.08842061 0.10104767]\n",
      "-139.06929664339202\n",
      "[0.98644346 0.79656116 0.69119027 5.05954987 0.10752486]\n",
      "-139.93290886490826\n",
      "[0.97653037 0.85966931 0.59561155 5.06963994 0.10038827]\n",
      "-139.38464543610547\n",
      "[0.9845577  0.77260608 0.70190552 5.06697797 0.10725061]\n",
      "-139.90446745172136\n",
      "[0.98284443 0.83530648 0.66681432 5.0697069  0.10668833]\n",
      "-140.01939758835817\n",
      "[0.98328719 0.86832033 0.66204424 5.07141217 0.10784028]\n",
      "-140.0662662417902\n",
      "[0.98766967 0.78923169 0.71506298 5.05827597 0.11659986]\n",
      "-139.732648036174\n",
      "[0.98108629 0.82017311 0.65711764 5.07151121 0.10286909]\n",
      "-139.93738708272076\n",
      "[0.98961799 0.86472353 0.66628177 5.06868453 0.10896228]\n",
      "-140.1063676889795\n",
      "[0.9953634  0.91027661 0.66034023 5.06941291 0.11091578]\n",
      "-140.16417522838097\n",
      "[0.98830697 0.82898335 0.70018029 5.06521613 0.1050012 ]\n",
      "-140.18182004737855\n",
      "[0.99046634 0.82437924 0.725841   5.06265942 0.10272227]\n",
      "-140.19363186943212\n",
      "[0.99010097 0.9152781  0.65670782 5.06684027 0.1054983 ]\n",
      "-140.2531168614857\n",
      "[0.99287261 0.98661411 0.63410897 5.06677141 0.10462215]\n",
      "-140.26071701455254\n",
      "[0.99078687 0.9673442  0.64459056 5.07715698 0.10406297]\n",
      "-140.18372783487592\n",
      "[1.         1.         0.67365236 5.06745395 0.10919629]\n",
      "-140.27840220465436\n",
      "[1.         1.         0.68191973 5.06542533 0.11235989]\n",
      "-140.20338841899988\n",
      "[1.         1.         0.67336901 5.0659697  0.10476751]\n",
      "-140.34689938936458\n",
      "[1.         1.         0.67903139 5.06324846 0.10323113]\n",
      "-140.320387286996\n",
      "[0.99428693 1.         0.68028454 5.06659167 0.09923269]\n",
      "[0.99509428 0.93297206 0.6653263  5.0687076  0.10799501]\n",
      "-140.27721916362162\n",
      "[1.         0.93024196 0.70432849 5.05546785 0.10765832]\n",
      "-140.09911470642848\n",
      "[0.99323676 0.95806864 0.65952505 5.0717347  0.10496181]\n",
      "-140.31126514934567\n",
      "[1.         1.         0.59655168 5.07359552 0.10989484]\n",
      "-139.96692998305457\n",
      "[0.99335354 0.8999551  0.69351867 5.06539345 0.10451541]\n",
      "-140.3294486568779\n",
      "[0.99980122 0.92978421 0.71204758 5.06893235 0.10795226]\n",
      "-140.19926477564732\n",
      "[0.99460476 0.97240664 0.65359363 5.06731165 0.10545468]\n",
      "-140.32601604909948\n",
      "[0.99738374 0.99920009 0.67613718 5.06643778 0.10356327]\n",
      "[0.99566665 0.94952907 0.66802902 5.06814015 0.10688707]\n",
      "-140.31987771932302\n",
      "[0.99074468 0.91198378 0.66556178 5.0679659  0.1014383 ]\n",
      "-140.33731507572153\n",
      "[0.99651109 0.93548119 0.6821038  5.06217764 0.10426338]\n",
      "-140.3161428069707\n",
      "[0.99569251 0.94112805 0.67645911 5.0645669  0.10443799]\n",
      "-140.34653367851823\n",
      "[0.99409155 0.94066036 0.67697185 5.06434289 0.10135848]\n",
      "-140.3662767770406\n",
      "[0.993304   0.93622601 0.68144327 5.06244427 0.09859419]\n",
      "-140.33823361498025\n",
      "[0.99494815 0.90508428 0.70075854 5.06398389 0.1011524 ]\n",
      "-140.36414049194278\n",
      "[0.99683722 0.97958749 0.66372945 5.06533827 0.10074646]\n",
      "-140.3722766989658\n",
      "[0.99857906 1.         0.64883484 5.06531068 0.09886199]\n",
      "[1.         0.9946003  0.6909534  5.06171476 0.10354683]\n",
      "-140.2703341465584\n",
      "[0.99352928 0.93263791 0.67190969 5.06640312 0.10196544]\n",
      "-140.37250205896885\n",
      "[0.99606997 0.96205996 0.67823631 5.06584825 0.09955813]\n",
      "-140.40783998578013\n",
      "[0.9962587  0.97252592 0.67912491 5.06648892 0.09711819]\n",
      "-140.42838436226825\n",
      "[0.99026596 0.89219838 0.68362877 5.06465314 0.09616888]\n",
      "-140.3646713899345\n",
      "[0.99344494 0.98195974 0.64938732 5.06690664 0.09779058]\n",
      "-140.3553491408111\n",
      "[0.99457235 0.92430315 0.68791574 5.06471458 0.10031195]\n",
      "-140.3881218883343\n",
      "[0.99984968 1.         0.66823188 5.06626197 0.10443133]\n",
      "[0.99266189 0.92107067 0.67977955 5.06505535 0.09823449]\n",
      "-140.38868687165805\n",
      "[0.99545223 0.95138969 0.67601188 5.0668572  0.09799213]\n",
      "-140.4293626909572\n",
      "[0.99613257 0.95675436 0.67553189 5.06811435 0.09630895]\n",
      "-140.45655987913537\n",
      "[0.9924247  0.90332931 0.69397526 5.06697226 0.09682915]\n",
      "-140.44322380035197\n",
      "[0.9952908  0.93855545 0.69462125 5.06613506 0.09355566]\n",
      "-140.45830289521555\n",
      "[0.99617155 0.94151423 0.70597703 5.06600104 0.08935077]\n",
      "-140.4582062540056\n",
      "[0.99453512 0.95259114 0.6812974  5.06839179 0.09250663]\n",
      "-140.48683711610536\n",
      "[0.9945165  0.96673513 0.67798823 5.0702304  0.08860398]\n",
      "-140.51621621962653\n",
      "[0.99718741 0.97408939 0.68871707 5.07012105 0.09073188]\n",
      "-140.51566184262762\n",
      "[0.99396209 0.92325954 0.69320857 5.07014033 0.08929365]\n",
      "-140.54970038100547\n",
      "[0.99281378 0.89862636 0.7002504  5.07196604 0.08538138]\n",
      "-140.60207359667865\n",
      "[0.99795173 0.99057497 0.68086828 5.0716545  0.08500359]\n",
      "-140.530202598795\n",
      "[0.99497152 0.95067817 0.7014462  5.07192847 0.08100164]\n",
      "-140.59231654177967\n",
      "[0.99568558 0.97372615 0.68508683 5.07622512 0.07873333]\n",
      "-140.62202156363068\n",
      "[0.99588297 0.99131151 0.68031962 5.08127015 0.07132216]\n",
      "-140.63936816808456\n",
      "[0.99326718 0.94508106 0.68763203 5.07669877 0.07379322]\n",
      "-140.64585748144702\n",
      "[0.99130707 0.93057689 0.68708951 5.07998763 0.06532389]\n",
      "-140.65640220288532\n",
      "[0.99465433 0.93797202 0.70200137 5.08049232 0.06660909]\n",
      "-140.72721751178977\n",
      "[0.99472324 0.92359046 0.71400794 5.08562327 0.05561164]\n",
      "-140.78084979709004\n",
      "[0.98992771 0.88733839 0.71237719 5.08465572 0.05845269]\n",
      "-140.79992341777086\n",
      "[0.9859157  0.83572009 0.72813165 5.09115633 0.04517724]\n",
      "-140.81837114381702\n",
      "[0.98928558 0.88125196 0.70247345 5.0920729  0.04812489]\n",
      "-140.7497771134457\n",
      "[0.99003204 0.92635401 0.70455846 5.10007808 0.02884255]\n",
      "-140.56732660927713\n",
      "[0.99211835 0.90555827 0.70132742 5.07899405 0.07124667]\n",
      "-140.72939433783353\n",
      "[0.985457   0.79936757 0.73289237 5.08986353 0.04287157]\n",
      "-140.7362461802091\n",
      "[0.98769288 0.80761845 0.74444362 5.0950964  0.03988892]\n",
      "-140.85713339622419\n",
      "[0.98588578 0.74613924 0.77312067 5.10265078 0.02717143]\n",
      "-140.75159738307653\n",
      "[0.98511141 0.79346114 0.74745219 5.10253092 0.02142303]\n",
      "-140.59607626851107\n",
      "[0.99036661 0.87753399 0.71285861 5.08487827 0.05879076]\n",
      "-140.80618738401884\n",
      "[0.9937366  0.93091842 0.70787374 5.08966734 0.05616581]\n",
      "-140.79271043518986\n",
      "[0.99168843 0.86890061 0.74045278 5.08649574 0.05412886]\n",
      "-140.88528621319415\n",
      "[0.99288985 0.86272493 0.75944244 5.08370716 0.05713085]\n",
      "-140.86952332777662\n",
      "[0.98503684 0.80468616 0.73949622 5.09329436 0.04604899]\n",
      "-140.8652711133039\n",
      "[0.98254358 0.7468653  0.75827941 5.0907011  0.0414481 ]\n",
      "-140.749387507191\n",
      "[0.99093835 0.88490514 0.72047516 5.08992578 0.05248638]\n",
      "-140.85196059089603\n",
      "[0.98614226 0.80319819 0.75634115 5.09750917 0.0363014 ]\n",
      "-140.8764555610082\n",
      "[0.99068381 0.83200333 0.75235192 5.09377225 0.04636458]\n",
      "-140.94117508481315\n",
      "[0.99306786 0.83014494 0.76446206 5.09508021 0.04695824]\n",
      "-140.95697230656054\n",
      "[0.98651296 0.7609142  0.77760317 5.09706457 0.03684418]\n",
      "-140.89666096078605\n",
      "[0.98928647 0.81951919 0.76689853 5.09268122 0.04822376]\n",
      "-140.96401215898484\n",
      "[0.99008327 0.82546956 0.77812599 5.09147364 0.05239118]\n",
      "-140.94813884231434\n",
      "[0.99364235 0.8283847  0.78280686 5.09423801 0.04293358]\n",
      "-140.94442897295238\n",
      "[0.99553697 0.83994726 0.77654821 5.08871473 0.05533405]\n",
      "-140.92478443293612\n",
      "[0.99153022 0.76266351 0.80687475 5.10061576 0.03798867]\n",
      "-140.9193598343972\n",
      "[0.99871258 0.87134964 0.78143299 5.0914674  0.05573114]\n",
      "-140.83257158422538\n",
      "[0.98956287 0.78852306 0.77856063 5.09566528 0.04156592]\n",
      "-140.95882475144435\n",
      "[0.99290839 0.87994415 0.74083576 5.08593602 0.05601756]\n",
      "-140.87911427611778\n",
      "[0.99187476 0.79198367 0.79036501 5.09694582 0.04249589]\n",
      "-140.96237890911556\n",
      "[0.98743676 0.78347496 0.77668903 5.10112949 0.0335369 ]\n",
      "-140.8984583838234\n",
      "[0.99351191 0.82582919 0.77658341 5.09181842 0.04988477]\n",
      "-140.959829355487\n",
      "[0.9892792  0.79401533 0.76794099 5.09463837 0.04871785]\n",
      "-140.95447917786527\n",
      "[0.99036999 0.80260767 0.77165746 5.09453828 0.04727178]\n",
      "-140.9672768930061\n",
      "[0.98877454 0.78124017 0.78916396 5.0935794  0.0448186 ]\n",
      "-140.96288787866072\n",
      "[0.9919642  0.81994889 0.77930672 5.09215998 0.051512  ]\n",
      "-140.95460558996504\n",
      "[0.9901632  0.79637952 0.77874715 5.09478895 0.04405244]\n",
      "-140.96879540848687\n",
      "[0.98667567 0.7708629  0.78214943 5.09719506 0.04086022]\n",
      "-140.94474881446797\n",
      "[0.99180285 0.81208762 0.77797492 5.09316258 0.04762863]\n",
      "-140.96968964345734\n",
      "[0.98828406 0.81275    0.7634118  5.09055435 0.05030219]\n",
      "-140.95498124163595\n",
      "[0.99097709 0.79717525 0.7836267  5.09534796 0.04444747]\n",
      "-140.96977713164344\n",
      "[0.9922653  0.82986753 0.76239795 5.09462819 0.04783103]\n",
      "-140.95644868850368\n",
      "[0.98964723 0.79339701 0.78247245 5.0938416  0.04557171]\n",
      "-140.96984846743464\n",
      "[0.99189767 0.78113964 0.79089294 5.09599052 0.04336505]\n",
      "-140.96615821573158\n",
      "[0.99124487 0.79073453 0.78489434 5.0951632  0.04457973]\n",
      "-140.9704971773143\n",
      "[0.99116411 0.7933019  0.79142877 5.09438344 0.04324021]\n",
      "-140.9623794181528\n",
      "[0.99056852 0.80028123 0.77660029 5.09449957 0.04626389]\n",
      "-140.9708839679949\n",
      "[0.99153302 0.80109073 0.78348033 5.09401701 0.04734413]\n",
      "-140.96945563243406\n",
      "[0.99119057 0.79991293 0.78229703 5.09420999 0.04652121]\n",
      "-140.9711440591761\n",
      "[0.98964846 0.78051276 0.78598141 5.09606235 0.04332497]\n",
      "-140.96437715855552\n",
      "[0.99126425 0.8041939  0.77997654 5.09388752 0.04655271]\n",
      "-140.97151941125477\n",
      "[0.99058909 0.79823259 0.77886956 5.0932928  0.04734823]\n",
      "-140.9716017926784\n",
      "[0.99039509 0.79876125 0.77649098 5.09226522 0.04879862]\n",
      "-140.96964601637893\n",
      "[0.99229569 0.80394506 0.77858265 5.09457963 0.0469346 ]\n",
      "-140.97114099241713\n",
      "[0.99111838 0.81189176 0.77363609 5.09302461 0.04886853]\n",
      "-140.96920040497665\n",
      "[0.99121325 0.79602383 0.78207978 5.09462855 0.04565193]\n",
      "-140.97176192880332\n",
      "[0.99205262 0.8006421  0.78412194 5.09373983 0.04693959]\n",
      "-140.97069482569472\n",
      "[0.99093954 0.80037144 0.7784807  5.09430963 0.04643281]\n",
      "-140.9717423665894\n",
      "[0.98978299 0.79554882 0.78209879 5.09355177 0.04606816]\n",
      "-140.97015687396942\n",
      "[0.99166752 0.801846   0.77946168 5.09432266 0.04671799]\n",
      "-140.97187160981932\n",
      "[0.99107889 0.80035418 0.77725027 5.09396647 0.04656027]\n",
      "-140.97215252434185\n",
      "[0.99102306 0.8005748  0.77472688 5.09384471 0.0465798 ]\n",
      "-140.9713645798942\n",
      "[0.99093106 0.79453731 0.77848025 5.09432053 0.04653178]\n",
      "-140.97144620886166\n",
      "[0.99118096 0.80177976 0.77960247 5.09399577 0.04654748]\n",
      "-140.9720121041275\n",
      "[0.99184297 0.8019175  0.7798804  5.09519644 0.04541596]\n",
      "-140.97087700739377\n",
      "[0.99090256 0.79915381 0.77912227 5.09376871 0.04686516]\n",
      "-140.9720861004017\n",
      "[0.99147773 0.79929159 0.78052589 5.09396323 0.04650432]\n",
      "-140.97250416616998\n",
      "[0.99174682 0.79875166 0.78154848 5.09379003 0.04654007]\n",
      "-140.9726021495795\n",
      "[0.99141745 0.80473033 0.77671429 5.09330891 0.04764046]\n",
      "-140.97199403736948\n",
      "[0.99086316 0.80006189 0.77823343 5.09320929 0.04694339]\n",
      "-140.9717730323405\n",
      "[0.99146643 0.80139997 0.77915462 5.09404432 0.04677434]\n",
      "-140.97226398192697\n",
      "[0.99113281 0.79584542 0.78195695 5.09451721 0.04567447]\n",
      "-140.97185436717498\n",
      "[0.99134629 0.8025091  0.77802496 5.09361099 0.04714896]\n",
      "-140.97229910929093\n",
      "[0.99143544 0.79908773 0.77843777 5.09367644 0.04700804]\n",
      "-140.97268224772776\n",
      "[0.99156268 0.79774172 0.77785542 5.09351677 0.04723832]\n",
      "-140.97273635882533\n",
      "[0.99197788 0.80114884 0.77841123 5.09380273 0.04683962]\n",
      "-140.97312377943348\n",
      "[0.99251554 0.80214635 0.77805571 5.09381973 0.04682685]\n",
      "-140.9735698248653\n",
      "[0.99237621 0.80066534 0.78060541 5.09354627 0.04725115]\n",
      "-140.97298193426545\n",
      "[0.99235259 0.7993257  0.77928137 5.09326919 0.0472278 ]\n",
      "-140.97350783556678\n",
      "[0.99287525 0.79694321 0.7809136  5.09356581 0.04688472]\n",
      "-140.97412463355107\n",
      "[0.99363972 0.79416026 0.78235792 5.09354323 0.04675259]\n",
      "-140.9747710644388\n",
      "[0.99323188 0.79886409 0.77771385 5.09328804 0.04757862]\n",
      "-140.97447375058067\n",
      "[0.9940837  0.80032298 0.78135029 5.09346982 0.04701648]\n",
      "-140.9746297596723\n",
      "[0.99395317 0.79726241 0.77889825 5.09340974 0.04690979]\n",
      "-140.97550805252314\n",
      "[0.99474165 0.79556094 0.77804467 5.09334148 0.0467391 ]\n",
      "-140.97619491842505\n",
      "[0.99493241 0.79709615 0.77972761 5.09371572 0.04673765]\n",
      "-140.97658538509808\n",
      "[0.99622231 0.79598137 0.77995072 5.09393899 0.04649258]\n",
      "-140.97797955147158\n",
      "[0.99625216 0.7918095  0.78171127 5.09321288 0.0470049 ]\n",
      "-140.97774304786478\n",
      "[0.99674394 0.79226993 0.7836521  5.09371451 0.04602365]\n",
      "-140.97791321502078\n",
      "[0.99695621 0.78758982 0.78093639 5.09363062 0.04618865]\n",
      "-140.97840962947527\n",
      "[0.99839247 0.78122325 0.78072944 5.09371102 0.04577473]\n",
      "-140.9782302588112\n",
      "[0.99872679 0.79112437 0.77936014 5.09359217 0.04622696]\n",
      "-140.98067605976468\n",
      "[1.         0.78960642 0.77786124 5.09361664 0.04596414]\n",
      "-140.98130254576918\n",
      "[0.99972821 0.78734188 0.78360002 5.09390398 0.04593047]\n",
      "-140.9815783804739\n",
      "[1.         0.78323236 0.78637769 5.09418524 0.04552615]\n",
      "-140.9808426534169\n",
      "[0.99960811 0.78930627 0.78068892 5.09430901 0.04523489]\n",
      "-140.98127570745166\n",
      "[1.         0.78766038 0.77756282 5.09404518 0.04590064]\n",
      "-140.98101080056196\n",
      "[1.         0.78062054 0.78030903 5.09386319 0.04519494]\n",
      "-140.97933480562028\n",
      "[1.         0.78622437 0.77907242 5.09426458 0.04510138]\n",
      "-140.98066737137987\n",
      "[0.99973452 0.79543519 0.77920514 5.09419257 0.04605767]\n",
      "-140.98155267974352\n",
      "[0.99962833 0.79351569 0.78049483 5.09376237 0.04653374]\n",
      "-140.98181357198592\n",
      "[0.9994425  0.79716134 0.78120603 5.09351127 0.04724992]\n",
      "-140.98058439112262\n",
      "[0.99947967 0.7944218  0.78317724 5.09386865 0.04598773]\n",
      "-140.9806828085554\n",
      "[0.99986992 0.78935074 0.77896642 5.09400105 0.04592241]\n",
      "-140.98173636152114\n",
      "[0.99997629 0.7927937  0.77936214 5.09348163 0.04692848]\n",
      "-140.98229044438958\n",
      "[1.         0.79453742 0.77869876 5.09306794 0.04777528]\n",
      "-140.98191860198224\n",
      "[0.99957491 0.79376846 0.78279018 5.09412001 0.04658497]\n",
      "-140.98062634781428\n",
      "[0.99989373 0.79064693 0.77909348 5.09374248 0.04611935]\n",
      "-140.98196453031545\n",
      "[0.99990406 0.78602438 0.78140162 5.09336404 0.04651611]\n",
      "-140.98174046309265\n",
      "[0.99998073 0.79359069 0.77612738 5.09343665 0.04687757]\n",
      "-140.98162450010346\n",
      "[0.9999176  0.79202849 0.77799554 5.09355348 0.0466408 ]\n",
      "-140.98201842474168\n",
      "[0.99985809 0.79265294 0.78037262 5.09316055 0.04717298]\n",
      "-140.98196812623127\n",
      "[0.99980555 0.79863071 0.77752583 5.09371617 0.04684203]\n",
      "-140.98148812270077\n",
      "[0.99987943 0.78917597 0.78043267 5.09345207 0.04659759]\n",
      "-140.98209887084184\n",
      "[1.         0.78940352 0.77840775 5.09319371 0.04684994]\n",
      "-140.98178907216754\n",
      "[0.99976668 0.79248765 0.77997306 5.09362021 0.04661279]\n",
      "-140.98208333266547\n",
      "[0.99986551 0.79300856 0.78016094 5.0931647  0.04746171]\n",
      "-140.9819030219283\n",
      "[0.99988667 0.79123734 0.77936034 5.09359804 0.04645494]\n",
      "-140.9821468588342\n",
      "[0.99991258 0.79043632 0.77847688 5.09392162 0.04612086]\n",
      "-140.98185992287887\n",
      "[0.99987171 0.79209878 0.77989869 5.09335082 0.04690995]\n",
      "-140.9821534330009\n",
      "[0.99983472 0.79108888 0.78161522 5.09344763 0.04676071]\n",
      "-140.98199420690662\n",
      "[0.99989688 0.79179359 0.77890046 5.09352702 0.04667077]\n",
      "-140.98215980052998\n",
      "[1.         0.7903521  0.77920866 5.09334362 0.0468119 ]\n",
      "-140.98219008846263\n",
      "[0.99997318 0.79413424 0.77825945 5.09346838 0.04691283]\n",
      "-140.98219016604435\n",
      "[1.         0.79323163 0.77889142 5.09327055 0.04723864]\n",
      "-140.98222263037405\n",
      "[1.         0.79282332 0.77795017 5.09348566 0.0469151 ]\n",
      "-140.9821743686085\n",
      "[1.         0.79354041 0.77856827 5.09329292 0.04725201]\n",
      "-140.9822046474746\n",
      "[0.99997979 0.79279751 0.77976581 5.09325718 0.04714244]\n",
      "-140.98220979392687\n",
      "[0.9999717  0.79624689 0.77873018 5.09336465 0.04737786]\n",
      "-140.98192297295077\n",
      "[0.99999293 0.7918258  0.77908904 5.09334888 0.04695339]\n",
      "-140.98226705637606\n",
      "[1.         0.79154138 0.78001123 5.09319209 0.04729316]\n",
      "-140.98218662904645\n",
      "[0.99998149 0.79348602 0.77869739 5.09339931 0.04700791]\n",
      "-140.98224205916011\n",
      "[0.9999722  0.79211346 0.77975405 5.0934101  0.04685634]\n",
      "-140.9822894937945\n",
      "[0.99998937 0.79258273 0.77855181 5.09350701 0.04685146]\n",
      "-140.98225461936377\n",
      "[0.99996491 0.79188906 0.77929035 5.09358822 0.0466004 ]\n",
      "-140.9822824067173\n",
      "[0.99997678 0.79099587 0.77972157 5.09353503 0.04666812]\n",
      "-140.98231042446508\n",
      "[0.99997443 0.7897508  0.78023365 5.09360288 0.04649822]\n",
      "-140.982280989123\n",
      "[0.99996387 0.79126442 0.78033506 5.09343853 0.04675123]\n",
      "-140.98228007712748\n",
      "[0.99994869 0.7917968  0.78029623 5.09363253 0.04656844]\n",
      "-140.98229129393698\n",
      "[0.99997168 0.79257113 0.77903468 5.09362047 0.04669748]\n",
      "-140.98228301801842\n",
      "[0.99997335 0.79221933 0.77997711 5.09348368 0.04688714]\n",
      "-140.9822971582966\n",
      "[0.99996724 0.79139653 0.78060976 5.09339672 0.04686593]\n",
      "-140.98225157971217\n",
      "[0.99997057 0.79227748 0.77942845 5.09356453 0.04673959]\n",
      "-140.98230891043195\n",
      "[0.99996608 0.79191982 0.77976015 5.09366886 0.04666037]\n",
      "-140.98231131022476\n",
      "[0.99996302 0.791823   0.7797632  5.09379824 0.04656239]\n",
      "-140.98227673217235\n",
      "[0.9999579  0.79089002 0.78031126 5.09367222 0.04648098]\n",
      "-140.98230660452438\n",
      "[0.99998918 0.79152421 0.77938319 5.0935372  0.04680605]\n",
      "-140.98232118771983\n",
      "[1.         0.79138791 0.77892667 5.09348954 0.04692485]\n",
      "-140.98227639579852\n",
      "[0.99997086 0.79082363 0.77946473 5.09370745 0.0464549 ]\n",
      "-140.98226752296873\n",
      "[0.99997272 0.7918704  0.77984902 5.09353963 0.04677908]\n",
      "-140.98232048709323\n",
      "[0.99999223 0.79254509 0.77894569 5.09346588 0.0469803 ]\n",
      "-140.98228759953898\n",
      "[0.99996648 0.79130379 0.77996987 5.09362063 0.04660581]\n",
      "-140.9823216121038\n",
      "[0.99997793 0.79076816 0.78004506 5.09359601 0.04666818]\n",
      "-140.98233001206984\n",
      "[0.99998161 0.79001349 0.78035337 5.09361175 0.04663247]\n",
      "-140.9823209974394\n",
      "[0.99997217 0.79195868 0.77988135 5.09364991 0.04673968]\n",
      "-140.98231045984863\n",
      "[0.99997333 0.79171798 0.7798414  5.09362119 0.04672179]\n",
      "-140.98232364664744\n",
      "[0.99998578 0.79095399 0.77987526 5.093497   0.04677199]\n",
      "-140.98232553393257\n",
      "[0.99998436 0.79063684 0.7797969  5.09360919 0.04665044]\n",
      "-140.982323512359\n",
      "[0.99996597 0.7906281  0.78042821 5.0936404  0.04656124]\n",
      "-140.98231757380063\n",
      "[0.99998338 0.79130018 0.77964444 5.093563   0.04674484]\n",
      "-140.9823288498884\n",
      "[0.99999542 0.79084707 0.77971136 5.09353392 0.04681709]\n",
      "-140.98232973954413\n",
      "[0.99998198 0.79159811 0.77985012 5.09351526 0.04683911]\n",
      "-140.98232622841277\n",
      "[0.99999647 0.79046903 0.7798091  5.09346089 0.0468147 ]\n",
      "-140.98231197311486\n",
      "[0.99997911 0.79140574 0.77983333 5.09358111 0.04674502]\n",
      "-140.98233145318738\n",
      "[0.99998135 0.7914137  0.77975846 5.09361872 0.0467537 ]\n",
      "-140.98232710456824\n",
      "[0.9999849  0.79069583 0.77974695 5.09364185 0.04665242]\n",
      "-140.98232227393848\n",
      "[0.99998271 0.79137254 0.77982432 5.09354691 0.04679244]\n",
      "-140.9823315479183\n",
      "[0.99998607 0.79086377 0.77986495 5.09350966 0.04675332]\n",
      "-140.98232573432293\n",
      "[0.99998253 0.79127622 0.77978508 5.09359146 0.04675361]\n",
      "-140.9823315722531\n",
      "[0.9999837  0.79096771 0.78003522 5.09357676 0.04676569]\n",
      "-140.98233303713243\n",
      "[0.99998387 0.79080147 0.78023061 5.09358364 0.04677611]\n",
      "-140.9823281805802\n",
      "[0.99996697 0.79146907 0.78009785 5.09362298 0.04667288]\n",
      "-140.98232186399537\n",
      "[0.99998831 0.79100257 0.77980798 5.09355618 0.04678104]\n",
      "-140.98233323638902\n",
      "[0.99998862 0.79164176 0.77966931 5.09354496 0.04686694]\n",
      "-140.9823262447289\n",
      "[0.9999806  0.79098656 0.77995113 5.09358325 0.04671787]\n",
      "-140.9823328708285\n",
      "[0.99998803 0.7908365  0.77992817 5.09356071 0.04677924]\n",
      "-140.9823329865877\n",
      "[0.99998656 0.79065528 0.77997871 5.09360044 0.04672654]\n",
      "-140.98233207101464\n",
      "[0.99998835 0.79050323 0.7800954  5.09355948 0.04675454]\n",
      "-140.98233119818738\n",
      "[0.99998398 0.79108297 0.77986266 5.09358346 0.04675384]\n",
      "-140.9823332080814\n",
      "[0.99998831 0.79100257 0.77980798 5.09355618 0.04678104]\n",
      "-140.98233323638902\n",
      "Time elapsed: 0.09 seconds\n",
      "Model estimated using ES() function: ETS(AAdN)\n",
      "With optimal initialisation\n",
      "Distribution assumed in the model: Normal\n",
      "Loss function type: likelihood; Loss function value: -140.9823\n",
      "Persistence vector g:\n",
      " alpha   beta\n",
      "1.0000 0.7910\n",
      "Damping parameter: 0.7798\n",
      "Sample size: 56\n",
      "Number of estimated parameters: 6\n",
      "Number of degrees of freedom: 50\n",
      "Information criteria:\n",
      "      AIC      AICc       BIC      BICc\n",
      "-269.9647 -268.2504 -257.8126 -254.3623\n"
     ]
    }
   ],
   "source": [
    "from smooth.adam_general.core.utils.utils import msdecompose\n",
    "\n",
    "series = datasets[349]\n",
    "\n",
    "print(series.x)\n",
    "\n",
    "test = msdecompose(series.x, lags=[1])\n",
    "\n",
    "# Fit model\n",
    "model = ES(model=\"AAdN\", lags=[1, series.period], initial=\"optimal\")\n",
    "model.fit(series.x)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-functions-header",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "evaluation-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_single_series(series, method_name):\n",
    "    \"\"\"\n",
    "    Evaluate a single method on a single series.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series : MCompSeries\n",
    "        Series to evaluate\n",
    "    method_name : str\n",
    "        Name of the method to use\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (RMSSE, SAME, time_elapsed)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Determine lags and model based on period\n",
    "        period = series.period\n",
    "        if period > 1:\n",
    "            lags = [1, period]\n",
    "            model_str = \"ZXZ\"  # Auto-select including seasonality\n",
    "        else:\n",
    "            lags = [1]\n",
    "            model_str = \"ZXN\"  # Auto-select without seasonality for non-seasonal data\n",
    "        \n",
    "        # Select model class based on method\n",
    "        if \"ADAM\" in method_name:\n",
    "            model_class = ADAM\n",
    "        else:\n",
    "            model_class = ES\n",
    "        \n",
    "        if \"Back\" in method_name:\n",
    "            initial = \"backcasting\"\n",
    "        elif \"Opt\" in method_name:\n",
    "            initial = \"optimal\"\n",
    "        elif \"Two\" in method_name:\n",
    "            initial = \"two-stage\"\n",
    "        else:\n",
    "            initial = \"backcasting\"\n",
    "        \n",
    "        # Create and fit model\n",
    "        model = model_class(model=model_str, lags=lags, initial=initial)\n",
    "        model.fit(series.x)\n",
    "        \n",
    "        # Generate forecasts\n",
    "        forecasts = model.predict(h=series.h)\n",
    "        forecast_values = forecasts['mean'].values\n",
    "        \n",
    "        time_elapsed = time.time() - start_time\n",
    "        \n",
    "        # Calculate RMSSE\n",
    "        rmsse = RMSSE(series.xx, forecast_values, series.x)\n",
    "        same = SAME(series.xx, forecast_values, series.x)\n",
    "        \n",
    "        return (rmsse, same, time_elapsed)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "\n",
    "\n",
    "def evaluate_method_sequential(datasets, method_name, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a method on all datasets sequentially.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datasets : list\n",
    "        List of MCompSeries\n",
    "    method_name : str\n",
    "        Name of the method\n",
    "    verbose : bool\n",
    "        Whether to print progress\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Arrays of (RMSSE values, time values)\n",
    "    \"\"\"\n",
    "    n = len(datasets)\n",
    "    rmsse_values = np.full(n, np.nan)\n",
    "    same_values = np.full(n, np.nan)\n",
    "    time_values = np.full(n, np.nan)\n",
    "    \n",
    "    for i, series in enumerate(datasets):\n",
    "        if verbose and (i + 1) % 100 == 0:\n",
    "            print(f\"  {method_name}: {i + 1}/{n}\")\n",
    "        \n",
    "        rmsse, same, elapsed = evaluate_single_series(series, method_name)\n",
    "        rmsse_values[i] = rmsse\n",
    "        same_values[i] = same\n",
    "        time_values[i] = elapsed\n",
    "    \n",
    "    return rmsse_values, same_values, time_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-evaluation-header",
   "metadata": {},
   "source": [
    "## Run Evaluation\n",
    "\n",
    "This may take a while depending on the number of series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "run-small-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on first 10 series...\n",
      "ADAM ETS Back: Mean RMSSE = 5.9556, SAME = 6.4621, Time = 0.059s\n",
      "ADAM ETS Opt: Mean RMSSE = 6.4098, SAME = 6.9332, Time = 0.126s\n"
     ]
    }
   ],
   "source": [
    "# First, test on a small subset to make sure everything works\n",
    "test_datasets = datasets[:10]\n",
    "\n",
    "print(\"Testing on first 10 series...\")\n",
    "for method in methods_names[:2]:  # Test first 2 methods\n",
    "    rmsse_vals, same_vals, time_vals = evaluate_method_sequential(test_datasets, method, verbose=False)\n",
    "    print(f\"{method}: Mean RMSSE = {np.nanmean(rmsse_vals):.4f}, SAME = {np.nanmean(same_vals):.4f}, Time = {np.nanmean(time_vals):.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initialize-results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results array shape: (6, 4004, 3)\n",
      "Methods: ['ADAM ETS Back', 'ADAM ETS Opt', 'ADAM ETS Two', 'ES Back', 'ES Opt', 'ES Two']\n"
     ]
    }
   ],
   "source": [
    "# Initialize results array\n",
    "# Shape: (methods, datasets, metrics) where metrics = [RMSSE, SAME, Time]\n",
    "test_results = np.full((methods_number, dataset_length, 3), np.nan)\n",
    "\n",
    "print(f\"Results array shape: {test_results.shape}\")\n",
    "print(f\"Methods: {methods_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "run-full-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full evaluation sequentially (alternative to parallel)\n",
    "# Skip this cell if using parallel evaluation above\n",
    "\n",
    "# for j, method_name in enumerate(methods_names):\n",
    "#     print(f\"\\nEvaluating {method_name} ({j+1}/{methods_number})...\")\n",
    "#     start = time.time()\n",
    "#     \n",
    "#     rmsse_values, same_values, time_values = evaluate_method_sequential(datasets, method_name)\n",
    "#     \n",
    "#     test_results[j, :, 0] = rmsse_values\n",
    "#     test_results[j, :, 1] = same_values\n",
    "#     test_results[j, :, 2] = time_values\n",
    "#     \n",
    "#     total_time = time.time() - start\n",
    "#     print(f\"  Completed in {total_time:.1f}s\")\n",
    "#     print(f\"  Mean RMSSE: {np.nanmean(rmsse_values):.4f}\")\n",
    "#     print(f\"  Mean SAME: {np.nanmean(same_values):.4f}\")\n",
    "#     print(f\"  Mean Time per series: {np.nanmean(time_values):.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "en8djiptws7",
   "metadata": {},
   "source": [
    "## Parallel Evaluation\n",
    "\n",
    "Run evaluation using all CPU cores for faster processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "y8zr0q53z4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_task(args):\n",
    "    \"\"\"\n",
    "    Worker function for parallel evaluation.\n",
    "    Must be defined at module level for pickling.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args : tuple\n",
    "        (series_idx, series_data, method_name) where series_data is a dict\n",
    "        containing the series attributes needed for evaluation\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (series_idx, method_name, rmsse, same, time_elapsed)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import time\n",
    "    from smooth import ADAM, ES\n",
    "    \n",
    "    series_idx, series_data, method_name = args\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Reconstruct series data\n",
    "        x = series_data['x']\n",
    "        xx = series_data['xx']\n",
    "        h = series_data['h']\n",
    "        period = series_data['period']\n",
    "        \n",
    "        # Determine lags and model based on period\n",
    "        if period > 1:\n",
    "            lags = [1, period]\n",
    "            model_str = \"ZXZ\"\n",
    "        else:\n",
    "            lags = [1]\n",
    "            model_str = \"ZXN\"\n",
    "        \n",
    "        # Select model class based on method\n",
    "        if \"ADAM\" in method_name:\n",
    "            model_class = ADAM\n",
    "        else:\n",
    "            model_class = ES\n",
    "        \n",
    "        if \"Back\" in method_name:\n",
    "            initial = \"backcasting\"\n",
    "        elif \"Opt\" in method_name:\n",
    "            initial = \"optimal\"\n",
    "        elif \"Two\" in method_name:\n",
    "            initial = \"two-stage\"\n",
    "        else:\n",
    "            initial = \"backcasting\"\n",
    "        \n",
    "        # Create and fit model\n",
    "        model = model_class(model=model_str, lags=lags, initial=initial)\n",
    "        model.fit(x)\n",
    "        \n",
    "        # Generate forecasts\n",
    "        forecasts = model.predict(h=h)\n",
    "        forecast_values = forecasts['mean'].values\n",
    "        \n",
    "        time_elapsed = time.time() - start_time\n",
    "        \n",
    "        # Calculate metrics\n",
    "        holdout = np.asarray(xx)\n",
    "        actuals = np.asarray(x)\n",
    "        \n",
    "        # RMSSE\n",
    "        mse = np.mean((holdout - forecast_values) ** 2)\n",
    "        scale = np.mean(np.diff(actuals) ** 2)\n",
    "        rmsse = np.sqrt(mse / scale) if scale != 0 else np.nan\n",
    "        \n",
    "        # SAME\n",
    "        ame = np.abs(np.mean(holdout - forecast_values))\n",
    "        scale_same = np.mean(np.abs(np.diff(actuals)))\n",
    "        same = ame / scale_same if scale_same != 0 else np.nan\n",
    "        \n",
    "        return (series_idx, method_name, rmsse, same, time_elapsed)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return (series_idx, method_name, np.nan, np.nan, np.nan)\n",
    "\n",
    "\n",
    "def evaluate_parallel(datasets, methods_names, n_workers=None):\n",
    "    \"\"\"\n",
    "    Evaluate all methods on all datasets in parallel.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datasets : list\n",
    "        List of MCompSeries objects\n",
    "    methods_names : list\n",
    "        List of method names to evaluate\n",
    "    n_workers : int, optional\n",
    "        Number of parallel workers. Defaults to all CPU cores.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Results array of shape (n_methods, n_datasets, 3) containing\n",
    "        [RMSSE, SAME, time] for each method-dataset combination\n",
    "    \"\"\"\n",
    "    if n_workers is None:\n",
    "        n_workers = multiprocessing.cpu_count()\n",
    "    \n",
    "    n_methods = len(methods_names)\n",
    "    n_datasets = len(datasets)\n",
    "    \n",
    "    # Initialize results array\n",
    "    results = np.full((n_methods, n_datasets, 3), np.nan)\n",
    "    \n",
    "    # Prepare tasks: convert series to picklable dicts\n",
    "    tasks = []\n",
    "    for j, method_name in enumerate(methods_names):\n",
    "        for i, series in enumerate(datasets):\n",
    "            series_data = {\n",
    "                'x': np.asarray(series.x),\n",
    "                'xx': np.asarray(series.xx),\n",
    "                'h': series.h,\n",
    "                'period': series.period\n",
    "            }\n",
    "            tasks.append((i, series_data, method_name))\n",
    "    \n",
    "    print(f\"Starting parallel evaluation with {n_workers} workers...\")\n",
    "    print(f\"Total tasks: {len(tasks)} ({n_methods} methods  {n_datasets} series)\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    completed = 0\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "        futures = {executor.submit(_evaluate_task, task): task for task in tasks}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            series_idx, method_name, rmsse, same, elapsed = result\n",
    "            \n",
    "            # Find method index\n",
    "            method_idx = methods_names.index(method_name)\n",
    "            \n",
    "            # Store results\n",
    "            results[method_idx, series_idx, 0] = rmsse\n",
    "            results[method_idx, series_idx, 1] = same\n",
    "            results[method_idx, series_idx, 2] = elapsed\n",
    "            \n",
    "            completed += 1\n",
    "            if completed % 1000 == 0:\n",
    "                elapsed_total = time.time() - start_time\n",
    "                rate = completed / elapsed_total\n",
    "                remaining = (len(tasks) - completed) / rate\n",
    "                print(f\"  Progress: {completed}/{len(tasks)} ({100*completed/len(tasks):.1f}%) - \"\n",
    "                      f\"ETA: {remaining/60:.1f} min\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nCompleted in {total_time/60:.1f} minutes ({total_time:.1f}s)\")\n",
    "    print(f\"Average time per task: {total_time/len(tasks)*1000:.1f}ms\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "swpfq4ermj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPU cores: 32\n",
      "Starting parallel evaluation with 32 workers...\n",
      "Total tasks: 24024 (6 methods  4004 series)\n",
      "  Progress: 1000/24024 (4.2%) - ETA: 9.8 min\n",
      "  Progress: 2000/24024 (8.3%) - ETA: 6.6 min\n",
      "  Progress: 3000/24024 (12.5%) - ETA: 7.7 min\n",
      "  Progress: 4000/24024 (16.7%) - ETA: 8.3 min\n",
      "  Progress: 5000/24024 (20.8%) - ETA: 10.9 min\n",
      "  Progress: 6000/24024 (25.0%) - ETA: 9.8 min\n",
      "  Progress: 7000/24024 (29.1%) - ETA: 11.3 min\n",
      "  Progress: 8000/24024 (33.3%) - ETA: 12.5 min\n",
      "  Progress: 9000/24024 (37.5%) - ETA: 12.4 min\n",
      "  Progress: 10000/24024 (41.6%) - ETA: 11.0 min\n",
      "  Progress: 11000/24024 (45.8%) - ETA: 10.9 min\n",
      "  Progress: 12000/24024 (50.0%) - ETA: 10.8 min\n",
      "  Progress: 13000/24024 (54.1%) - ETA: 9.5 min\n",
      "  Progress: 14000/24024 (58.3%) - ETA: 8.2 min\n",
      "  Progress: 15000/24024 (62.4%) - ETA: 7.2 min\n",
      "  Progress: 16000/24024 (66.6%) - ETA: 6.3 min\n",
      "  Progress: 17000/24024 (70.8%) - ETA: 5.7 min\n",
      "  Progress: 18000/24024 (74.9%) - ETA: 4.7 min\n",
      "  Progress: 19000/24024 (79.1%) - ETA: 4.1 min\n",
      "  Progress: 20000/24024 (83.3%) - ETA: 3.5 min\n",
      "  Progress: 21000/24024 (87.4%) - ETA: 2.7 min\n",
      "  Progress: 22000/24024 (91.6%) - ETA: 1.7 min\n",
      "  Progress: 23000/24024 (95.7%) - ETA: 0.9 min\n",
      "  Progress: 24000/24024 (99.9%) - ETA: 0.0 min\n",
      "\n",
      "Completed in 21.7 minutes (1303.5s)\n",
      "Average time per task: 54.3ms\n",
      "\n",
      "Per-method summary:\n",
      "  ADAM ETS Back: RMSSE=2.0856, SAME=2.1031, Time=0.789s, Failed=0\n",
      "  ADAM ETS Opt: RMSSE=2.0778, SAME=2.0918, Time=2.192s, Failed=5\n",
      "  ADAM ETS Two: RMSSE=2.0778, SAME=2.0918, Time=2.196s, Failed=5\n",
      "  ES Back: RMSSE=2.0850, SAME=2.1041, Time=0.803s, Failed=0\n",
      "  ES Opt: RMSSE=2.0802, SAME=2.0953, Time=2.249s, Failed=5\n",
      "  ES Two: RMSSE=2.0802, SAME=2.0953, Time=2.191s, Failed=5\n"
     ]
    }
   ],
   "source": [
    "# Run parallel evaluation using all CPU cores\n",
    "# This is much faster than sequential evaluation\n",
    "\n",
    "print(f\"Available CPU cores: {multiprocessing.cpu_count()}\")\n",
    "\n",
    "# Run parallel evaluation\n",
    "test_results = evaluate_parallel(datasets, methods_names)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nPer-method summary:\")\n",
    "for j, method in enumerate(methods_names):\n",
    "    rmsse_mean = np.nanmean(test_results[j, :, 0])\n",
    "    same_mean = np.nanmean(test_results[j, :, 1])\n",
    "    time_mean = np.nanmean(test_results[j, :, 2])\n",
    "    failed = np.sum(np.isnan(test_results[j, :, 0]))\n",
    "    print(f\"  {method}: RMSSE={rmsse_mean:.4f}, SAME={same_mean:.4f}, \"\n",
    "          f\"Time={time_mean:.3f}s, Failed={failed}\")\n",
    "\n",
    "np.save('2026-01-18-Mcomp-test.npy', test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-header",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "summarize-results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "       Method      Min       Q1     Mean      Med       Q3       Max  Mean SAME  Med SAME  Mean Time (s)  Failed\n",
      "ADAM ETS Back 0.018252 0.707183 2.085643 1.241253 2.547780 50.258736   2.103068  1.084022       0.803426       0\n",
      " ADAM ETS Opt 0.024155 0.695568 2.078898 1.268761 2.558321 51.616184   2.092810  1.105280       2.241774       0\n",
      " ADAM ETS Two 0.024925 0.700068 2.093054 1.265177 2.532407 51.616184   2.110408  1.103959       2.409651       0\n",
      "      ES Back 0.018252 0.705564 2.084956 1.244262 2.540733 50.258736   2.104058  1.079399       0.813481       0\n",
      "       ES Opt 0.024155 0.706472 2.081472 1.266547 2.556744 51.616184   2.096443  1.101234       2.163924       0\n",
      "       ES Two 0.024925 0.711859 2.103972 1.273581 2.576052 51.616184   2.126635  1.105244       2.315632       0\n"
     ]
    }
   ],
   "source": [
    "test_results = np.load('2026-01-18-Mcomp-test.npy')\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'Method': methods_names,\n",
    "    'Min': [np.nanmin(test_results[j, :, 0]) for j in range(methods_number)],\n",
    "    'Q1': [np.nanquantile(test_results[j, :, 0], 0.25) for j in range(methods_number)],\n",
    "    'Mean': [np.nanmean(test_results[j, :, 0]) for j in range(methods_number)],\n",
    "    'Med': [np.nanmedian(test_results[j, :, 0]) for j in range(methods_number)],\n",
    "    'Q3': [np.nanquantile(test_results[j, :, 0], 0.75) for j in range(methods_number)],\n",
    "    'Max': [np.nanmax(test_results[j, :, 0]) for j in range(methods_number)],\n",
    "    'Mean SAME': [np.nanmean(test_results[j, :, 1]) for j in range(methods_number)],\n",
    "    'Med SAME': [np.nanmedian(test_results[j, :, 1]) for j in range(methods_number)],\n",
    "    'Mean Time (s)': [np.nanmean(test_results[j, :, 2]) for j in range(methods_number)],\n",
    "    'Failed': [np.sum(np.isnan(test_results[j, :, 0])) for j in range(methods_number)]\n",
    "})\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-by-type",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results by series type\n",
    "series_types = [s.type for s in datasets]\n",
    "unique_types = list(set(series_types))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS BY SERIES TYPE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for stype in unique_types:\n",
    "    mask = np.array([s.type == stype for s in datasets])\n",
    "    print(f\"\\n{stype.upper()} ({np.sum(mask)} series):\")\n",
    "    \n",
    "    for j, method in enumerate(methods_names):\n",
    "        rmsse_type = test_results[j, mask, 0]\n",
    "        print(f\"  {method}: Mean RMSSE = {np.nanmean(rmsse_type):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import datetime\n",
    "import joblib\n",
    "\n",
    "date_str = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save as numpy array\n",
    "np.save(f'test_results_{date_str}.npy', test_results)\n",
    "\n",
    "# Save summary as CSV\n",
    "summary.to_csv(f'test_summary_{date_str}.csv', index=False)\n",
    "\n",
    "# Save complete results with metadata using joblib\n",
    "results_dict = {\n",
    "    'test_results': test_results,\n",
    "    'methods_names': methods_names,\n",
    "    'dataset_info': [(s.sn, s.type, s.period, len(s.x), s.h) for s in datasets],\n",
    "    'summary': summary\n",
    "}\n",
    "joblib.dump(results_dict, f'test_results_full_{date_str}.joblib')\n",
    "\n",
    "print(f\"Results saved:\")\n",
    "print(f\"  - test_results_{date_str}.npy (raw array)\")\n",
    "print(f\"  - test_summary_{date_str}.csv (summary table)\")\n",
    "print(f\"  - test_results_full_{date_str}.joblib (complete with metadata)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-series-header",
   "metadata": {},
   "source": [
    "## Single Series Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52aeb09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.13 5.16 5.17 5.2  5.22 5.2  5.24 5.26 5.27 5.3  5.32 5.34 5.39 5.43\n",
      " 5.45 5.49 5.54 5.57 5.59 5.59 5.58 5.54 5.53 5.54 5.54 5.56 5.6  5.6\n",
      " 5.6  5.59 5.57 5.53 5.5  5.48 5.44 5.45 5.49 5.54 5.58 5.63 5.68 5.69\n",
      " 5.71 5.72 5.73 5.74 5.77 5.79 5.78 5.78 5.81 5.83 5.86 5.9  5.91 5.94]\n",
      "Time elapsed: 0.02 seconds\n",
      "Model estimated using ES() function: ETS(AAdN)\n",
      "With backcasting initialisation\n",
      "Distribution assumed in the model: Normal\n",
      "Loss function type: likelihood; Loss function value: -138.2533\n",
      "Persistence vector g:\n",
      " alpha   beta\n",
      "1.0000 0.6923\n",
      "Damping parameter: 1.0000\n",
      "Sample size: 56\n",
      "Number of estimated parameters: 4\n",
      "Number of degrees of freedom: 52\n",
      "Information criteria:\n",
      "      AIC      AICc       BIC      BICc\n",
      "-268.5066 -267.7222 -260.4052 -258.8266\n"
     ]
    }
   ],
   "source": [
    "series = datasets[349]\n",
    "print(series.x)\n",
    "\n",
    "# Fit model\n",
    "model = ES(model=\"AAdN\", lags=[1, series.period], initial=\"backcasting\")\n",
    "model.fit(series.x)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-series-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a single series to see detailed output\n",
    "series = M3[203]\n",
    "print(f\"Series: {series}\")\n",
    "print(f\"Training length: {len(series.x)}\")\n",
    "print(f\"Test length: {len(series.xx)}\")\n",
    "print(f\"Period: {series.period}\")\n",
    "\n",
    "# Fit model\n",
    "model = ES(model=\"ZXZ\", lags=[1, series.period], initial=\"optimal\")\n",
    "model.fit(series.x)\n",
    "\n",
    "print(\"\\n\" + str(model))\n",
    "\n",
    "# Forecast\n",
    "forecasts = model.predict(h=series.h)\n",
    "print(\"\\nForecasts vs Actuals:\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Forecast': forecasts['mean'].values,\n",
    "    'Actual': series.xx,\n",
    "    'Error': forecasts['mean'].values - series.xx\n",
    "})\n",
    "print(comparison)\n",
    "\n",
    "# Calculate error metrics\n",
    "rmsse = RMSSE(series.xx, forecasts['mean'].values, series.x)\n",
    "print(f\"\\nRMSSE: {rmsse:.4f}\")\n",
    "\n",
    "same = SAME(series.xx, forecasts['mean'].values, series.x)\n",
    "print(f\"\\nSAME: {same:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kobeicx8348",
   "metadata": {},
   "source": [
    "## Parameter Distribution Analysis\n",
    "\n",
    "Record model types, loss values, smoothing and dampening parameters for distribution analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "j16fmq1bsoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_params_task(args):\n",
    "    \"\"\"\n",
    "    Worker function for parallel parameter extraction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args : tuple\n",
    "        (series_idx, series_data, method_name)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (series_idx, method_name, params_dict)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import time\n",
    "    from smooth import ADAM, ES\n",
    "    \n",
    "    series_idx, series_data, method_name = args\n",
    "    \n",
    "    # Initialize result dict with NaN/None defaults\n",
    "    params = {\n",
    "        'model_type': None,\n",
    "        'loss_value': np.nan,\n",
    "        'alpha': np.nan,\n",
    "        'beta': np.nan,\n",
    "        'gamma': np.nan,\n",
    "        'phi': np.nan,\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Reconstruct series data\n",
    "        x = series_data['x']\n",
    "        period = series_data['period']\n",
    "        \n",
    "        # Determine lags and model based on period\n",
    "        if period > 1:\n",
    "            lags = [1, period]\n",
    "            model_str = \"ZXZ\"\n",
    "        else:\n",
    "            lags = [1]\n",
    "            model_str = \"ZXN\"\n",
    "        \n",
    "        # Select model class based on method\n",
    "        if \"ADAM\" in method_name:\n",
    "            model_class = ADAM\n",
    "        else:\n",
    "            model_class = ES\n",
    "        \n",
    "        if \"Back\" in method_name:\n",
    "            initial = \"backcasting\"\n",
    "        elif \"Opt\" in method_name:\n",
    "            initial = \"optimal\"\n",
    "        elif \"Two\" in method_name:\n",
    "            initial = \"two-stage\"\n",
    "        else:\n",
    "            initial = \"backcasting\"\n",
    "        \n",
    "        # Create and fit model\n",
    "        model = model_class(model=model_str, lags=lags, initial=initial)\n",
    "        model.fit(x)\n",
    "        \n",
    "        # Extract the SELECTED model type (not the input model string)\n",
    "        # Construct from error_type, trend_type, season_type, and damped flag\n",
    "        if hasattr(model, 'model_type_dict') and model.model_type_dict:\n",
    "            error_type = model.model_type_dict.get('error_type', '')\n",
    "            trend_type = model.model_type_dict.get('trend_type', '')\n",
    "            season_type = model.model_type_dict.get('season_type', '')\n",
    "            damped = model.model_type_dict.get('damped', False)\n",
    "            \n",
    "            # Construct model string: e.g., \"MAN\", \"AAdA\", \"ANN\"\n",
    "            if error_type and trend_type is not None and season_type is not None:\n",
    "                selected_model = error_type + trend_type\n",
    "                if damped and trend_type != 'N':\n",
    "                    selected_model += 'd'\n",
    "                selected_model += season_type\n",
    "                params['model_type'] = selected_model\n",
    "        \n",
    "        # Extract loss value\n",
    "        if hasattr(model, 'adam_estimated') and model.adam_estimated:\n",
    "            params['loss_value'] = model.adam_estimated.get('CF_value', np.nan)\n",
    "        \n",
    "        # Extract smoothing parameters\n",
    "        if hasattr(model, 'persistence_level_') and model.persistence_level_ is not None:\n",
    "            params['alpha'] = float(model.persistence_level_)\n",
    "        \n",
    "        if hasattr(model, 'persistence_trend_') and model.persistence_trend_ is not None:\n",
    "            params['beta'] = float(model.persistence_trend_)\n",
    "        \n",
    "        if hasattr(model, 'persistence_seasonal_') and model.persistence_seasonal_ is not None:\n",
    "            gamma = model.persistence_seasonal_\n",
    "            if isinstance(gamma, (list, np.ndarray)) and len(gamma) > 0:\n",
    "                params['gamma'] = float(gamma[0])\n",
    "            elif isinstance(gamma, (int, float)):\n",
    "                params['gamma'] = float(gamma)\n",
    "        \n",
    "        # Extract dampening parameter\n",
    "        if hasattr(model, 'phi_') and model.phi_ is not None:\n",
    "            params['phi'] = float(model.phi_)\n",
    "        \n",
    "        return (series_idx, method_name, params)\n",
    "    \n",
    "    except Exception as e:\n",
    "        params['error'] = str(e)\n",
    "        return (series_idx, method_name, params)\n",
    "\n",
    "\n",
    "def extract_params_parallel(datasets, methods_names, n_workers=None):\n",
    "    \"\"\"\n",
    "    Extract model parameters for all methods on all datasets in parallel.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datasets : list\n",
    "        List of MCompSeries objects\n",
    "    methods_names : list\n",
    "        List of method names to evaluate\n",
    "    n_workers : int, optional\n",
    "        Number of parallel workers. Defaults to all CPU cores.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Nested dictionary with structure:\n",
    "        {\n",
    "            method_name: {\n",
    "                'model_types': [...],      # list of selected model types (e.g., 'AAN', 'MAdM')\n",
    "                'loss_values': [...],      # list of loss values\n",
    "                'alpha': [...],            # list of alpha (level smoothing) values\n",
    "                'beta': [...],             # list of beta (trend smoothing) values\n",
    "                'gamma': [...],            # list of gamma (seasonal smoothing) values\n",
    "                'phi': [...],              # list of phi (dampening) values\n",
    "                'errors': [...],           # list of error messages (None if success)\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    if n_workers is None:\n",
    "        n_workers = multiprocessing.cpu_count()\n",
    "    \n",
    "    n_methods = len(methods_names)\n",
    "    n_datasets = len(datasets)\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        method: {\n",
    "            'model_types': [None] * n_datasets,\n",
    "            'loss_values': [np.nan] * n_datasets,\n",
    "            'alpha': [np.nan] * n_datasets,\n",
    "            'beta': [np.nan] * n_datasets,\n",
    "            'gamma': [np.nan] * n_datasets,\n",
    "            'phi': [np.nan] * n_datasets,\n",
    "            'errors': [None] * n_datasets,\n",
    "        }\n",
    "        for method in methods_names\n",
    "    }\n",
    "    \n",
    "    # Prepare tasks\n",
    "    tasks = []\n",
    "    for method_name in methods_names:\n",
    "        for i, series in enumerate(datasets):\n",
    "            series_data = {\n",
    "                'x': np.asarray(series.x),\n",
    "                'period': series.period\n",
    "            }\n",
    "            tasks.append((i, series_data, method_name))\n",
    "    \n",
    "    print(f\"Starting parallel parameter extraction with {n_workers} workers...\")\n",
    "    print(f\"Total tasks: {len(tasks)} ({n_methods} methods  {n_datasets} series)\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    completed = 0\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "        futures = {executor.submit(_extract_params_task, task): task for task in tasks}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            series_idx, method_name, params = future.result()\n",
    "            \n",
    "            # Store results\n",
    "            results[method_name]['model_types'][series_idx] = params['model_type']\n",
    "            results[method_name]['loss_values'][series_idx] = params['loss_value']\n",
    "            results[method_name]['alpha'][series_idx] = params['alpha']\n",
    "            results[method_name]['beta'][series_idx] = params['beta']\n",
    "            results[method_name]['gamma'][series_idx] = params['gamma']\n",
    "            results[method_name]['phi'][series_idx] = params['phi']\n",
    "            results[method_name]['errors'][series_idx] = params['error']\n",
    "            \n",
    "            completed += 1\n",
    "            if completed % 1000 == 0:\n",
    "                elapsed_total = time.time() - start_time\n",
    "                rate = completed / elapsed_total\n",
    "                remaining = (len(tasks) - completed) / rate\n",
    "                print(f\"  Progress: {completed}/{len(tasks)} ({100*completed/len(tasks):.1f}%) - \"\n",
    "                      f\"ETA: {remaining/60:.1f} min\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nCompleted in {total_time/60:.1f} minutes ({total_time:.1f}s)\")\n",
    "    \n",
    "    # Convert lists to numpy arrays for easier analysis\n",
    "    for method in methods_names:\n",
    "        results[method]['loss_values'] = np.array(results[method]['loss_values'])\n",
    "        results[method]['alpha'] = np.array(results[method]['alpha'])\n",
    "        results[method]['beta'] = np.array(results[method]['beta'])\n",
    "        results[method]['gamma'] = np.array(results[method]['gamma'])\n",
    "        results[method]['phi'] = np.array(results[method]['phi'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8qovle0mmze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parallel parameter extraction with 32 workers...\n",
      "Total tasks: 24024 (6 methods  4004 series)\n",
      "  Progress: 1000/24024 (4.2%) - ETA: 9.8 min\n",
      "  Progress: 2000/24024 (8.3%) - ETA: 6.7 min\n",
      "  Progress: 3000/24024 (12.5%) - ETA: 7.8 min\n",
      "  Progress: 4000/24024 (16.7%) - ETA: 8.4 min\n",
      "  Progress: 5000/24024 (20.8%) - ETA: 11.1 min\n",
      "  Progress: 6000/24024 (25.0%) - ETA: 9.9 min\n",
      "  Progress: 7000/24024 (29.1%) - ETA: 11.4 min\n",
      "  Progress: 8000/24024 (33.3%) - ETA: 12.6 min\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  Progress: 9000/24024 (37.5%) - ETA: 12.7 min\n",
      "\n",
      "\n",
      "  Progress: 10000/24024 (41.6%) - ETA: 11.2 min\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  Progress: 11000/24024 (45.8%) - ETA: 11.2 min\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  Progress: 12000/24024 (50.0%) - ETA: 11.2 min\n",
      "\n",
      "  Progress: 13000/24024 (54.1%) - ETA: 9.8 min\n",
      "  Progress: 14000/24024 (58.3%) - ETA: 8.4 min\n",
      "  Progress: 15000/24024 (62.4%) - ETA: 7.4 min\n",
      "  Progress: 16000/24024 (66.6%) - ETA: 6.4 min\n",
      "  Progress: 17000/24024 (70.8%) - ETA: 5.8 min\n",
      "  Progress: 18000/24024 (74.9%) - ETA: 4.8 min\n",
      "  Progress: 19000/24024 (79.1%) - ETA: 4.2 min\n",
      "  Progress: 20000/24024 (83.3%) - ETA: 3.5 min\n",
      "\n",
      "\n",
      "\n",
      "  Progress: 21000/24024 (87.4%) - ETA: 2.7 min\n",
      "\n",
      "\n",
      "\n",
      "  Progress: 22000/24024 (91.6%) - ETA: 1.7 min\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  Progress: 23000/24024 (95.7%) - ETA: 0.9 min\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  Progress: 24000/24024 (99.9%) - ETA: 0.0 min\n",
      "\n",
      "Completed in 22.0 minutes (1319.5s)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2026-01-19-Mcomp-param_results.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, param_results)\n",
      "\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n",
      "\u001b[0;32m----> 7\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241m.\u001b[39mdump(param_results, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2026-01-19-Mcomp-params.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter results saved to 2026-01-19-Mcomp-params.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "# Run parallel parameter extraction\n",
    "param_results = extract_params_parallel(datasets, methods_names)\n",
    "\n",
    "np.save('2026-01-19-Mcomp-param_results.npy', param_results)\n",
    "\n",
    "# Save results\n",
    "joblib.dump(param_results, '2026-01-19-Mcomp-params.joblib')\n",
    "print(\"Parameter results saved to 2026-01-19-Mcomp-params.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "qpb72pctj8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL TYPE DISTRIBUTION BY METHOD\n",
      "======================================================================\n",
      "\n",
      "ADAM ETS Back:\n",
      "MAN     754\n",
      "MAA     434\n",
      "AAN     421\n",
      "MAM     375\n",
      "MNM     370\n",
      "MNN     243\n",
      "ANN     226\n",
      "ANA     219\n",
      "AAA     188\n",
      "MAdN    168\n",
      "\n",
      "ADAM ETS Opt:\n",
      "MAN     775\n",
      "MNN     605\n",
      "ANN     490\n",
      "AAN     392\n",
      "MAM     331\n",
      "MAdN    237\n",
      "MNA     226\n",
      "AAdN    213\n",
      "MNM     169\n",
      "ANM     148\n",
      "\n",
      "ADAM ETS Two:\n",
      "MAN     775\n",
      "MNN     605\n",
      "ANN     490\n",
      "AAN     392\n",
      "MAM     331\n",
      "MAdN    237\n",
      "MNA     226\n",
      "AAdN    213\n",
      "MNM     169\n",
      "ANM     148\n",
      "\n",
      "ES Back:\n",
      "MAN     754\n",
      "MAA     435\n",
      "AAN     417\n",
      "MAM     388\n",
      "MNM     375\n",
      "ANN     239\n",
      "MNN     229\n",
      "ANA     225\n",
      "AAA     190\n",
      "MAdN    166\n",
      "\n",
      "ES Opt:\n",
      "MAN     771\n",
      "MNN     621\n",
      "ANN     475\n",
      "AAN     380\n",
      "MAM     312\n",
      "MNA     232\n",
      "MAdN    227\n",
      "AAdN    225\n",
      "MNM     209\n",
      "ANA     126\n",
      "\n",
      "ES Two:\n",
      "MAN     771\n",
      "MNN     621\n",
      "ANN     475\n",
      "AAN     380\n",
      "MAM     312\n",
      "MNA     232\n",
      "MAdN    227\n",
      "AAdN    225\n",
      "MNM     209\n",
      "ANA     126\n"
     ]
    }
   ],
   "source": [
    "# param_results = np.load('2026-01-19-Mcomp-param_results.npy')\n",
    "\n",
    "# Analyze model type distributions\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL TYPE DISTRIBUTION BY METHOD\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for method in methods_names:\n",
    "    model_types = param_results[method]['model_types']\n",
    "    # Count occurrences of each model type\n",
    "    type_counts = pd.Series(model_types).value_counts()\n",
    "    print(f\"\\n{method}:\")\n",
    "    print(type_counts.head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dewllxjgw84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PARAMETER DISTRIBUTION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "ADAM ETS Back:\n",
      "------------------------------------------------------------\n",
      "    Parameter  Count     Mean      Std       Min      Q25   Median      Q75       Max  Where\n",
      "Phi (damping)     69   0.8913   0.1611    0.2581   0.8554   0.9470   1.0000    1.0000      0\n",
      "   Loss value   4004 399.4577 279.3122 -349.9066 169.2847 321.5593 600.6941 1401.8902    474\n",
      "\n",
      "ADAM ETS Opt:\n",
      "------------------------------------------------------------\n",
      "    Parameter  Count     Mean      Std       Min      Q25   Median      Q75       Max  Where\n",
      "Phi (damping)     70   0.8420   0.1383    0.4607   0.8180   0.8875   0.9447    0.9976      0\n",
      "   Loss value   4004 399.7592 278.6689 -349.3583 169.2995 320.7640 601.3232 1398.6604    474\n",
      "\n",
      "ADAM ETS Two:\n",
      "------------------------------------------------------------\n",
      "    Parameter  Count                                                                                                                                                                                                                                                                                                            Mean    Std       Min      Q25   Median      Q75                                                                                                                                                                                                                                                                                                                Max  Where\n",
      "Phi (damping)     70                                                                                                                                                                                                                                                                                                          0.8567 0.1200    0.5383   0.8212   0.8950   0.9457                                                                                                                                                                                                                                                                                                             1.0000      0\n",
      "   Loss value   4004 5744255744255744043211901397545139400383368254050717440397428317818994075527153037607690901702171889713490716168801536043224222618604604524666276460755599745899555421499421432984475058148816953536210616895204525224645124051819395127791557692277230352856919729692251177691487895799210185440911949824.0000    inf -349.1008 170.7723 323.6743 607.6329 1000000000000000052504760255204420248704468581108159154915854115511802457988908195786371375080447864043704443832883878176942523235360430575644792184786706982848387200926575803737830233794788090059368953234970799945081119038967640880074652742780142494579258788820056842838115669472196386865459400540160.0000    203\n",
      "\n",
      "ES Back:\n",
      "------------------------------------------------------------\n",
      "    Parameter  Count     Mean      Std       Min      Q25   Median      Q75       Max  Where\n",
      "Phi (damping)     69   0.9117   0.1485    0.2581   0.8950   0.9924   1.0000    1.0000      0\n",
      "   Loss value   4004 399.6591 279.7043 -349.8995 169.2656 321.1081 600.7808 1403.6539    474\n",
      "\n",
      "ES Opt:\n",
      "------------------------------------------------------------\n",
      "    Parameter  Count     Mean      Std       Min      Q25   Median      Q75       Max  Where\n",
      "Phi (damping)     72   0.8454   0.1407    0.4141   0.8073   0.8895   0.9478    1.0000      0\n",
      "   Loss value   4004 399.8961 278.8322 -349.3583 170.0899 320.6184 601.2995 1399.4928    474\n",
      "\n",
      "ES Two:\n",
      "------------------------------------------------------------\n",
      "    Parameter  Count                                                                                                                                                                                                                                                                                                            Mean    Std       Min      Q25   Median      Q75                                                                                                                                                                                                                                                                                                                Max  Where\n",
      "Phi (damping)     72                                                                                                                                                                                                                                                                                                          0.8696 0.1229    0.5303   0.8324   0.9067   0.9563                                                                                                                                                                                                                                                                                                             1.0000      0\n",
      "   Loss value   4004 5494505494505494857813625564214837509968856307166248796380903521845174007484207948858009665637950727282043411176403116262335455199137541386380436349485070466836544592247438558611483103244881072728607308051768512328707890596638703585049118215733959798387880551065648991042406900179646735171023011840.0000    inf -349.1008 170.9447 323.2998 608.5151 1000000000000000052504760255204420248704468581108159154915854115511802457988908195786371375080447864043704443832883878176942523235360430575644792184786706982848387200926575803737830233794788090059368953234970799945081119038967640880074652742780142494579258788820056842838115669472196386865459400540160.0000    349\n"
     ]
    }
   ],
   "source": [
    "# Parameter distribution summary\n",
    "print(\"=\" * 70)\n",
    "print(\"PARAMETER DISTRIBUTION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "param_names = ['alpha', 'beta', 'gamma', 'phi', 'loss_values']\n",
    "param_labels = ['Alpha (level)', 'Beta (trend)', 'Gamma (seasonal)', 'Phi (damping)', 'Loss value']\n",
    "\n",
    "for method in methods_names:\n",
    "    print(f\"\\n{method}:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    summary_data = []\n",
    "    for param, label in zip(param_names, param_labels):\n",
    "        values = param_results[method][param]\n",
    "        valid = values[~np.isnan(values)]\n",
    "        if len(valid) > 0:\n",
    "            summary_data.append({\n",
    "                'Parameter': label,\n",
    "                'Count': len(valid),\n",
    "                'Mean': np.mean(valid),\n",
    "                'Std': np.std(valid),\n",
    "                'Min': np.min(valid),\n",
    "                'Q25': np.percentile(valid, 25),\n",
    "                'Median': np.median(valid),\n",
    "                'Q75': np.percentile(valid, 75),\n",
    "                'Max': np.max(valid),\n",
    "                'Where': np.argmax(values)\n",
    "            })\n",
    "    \n",
    "    if summary_data:\n",
    "        df = pd.DataFrame(summary_data)\n",
    "        print(df.to_string(index=False, float_format=lambda x: f'{x:.4f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421g1uahfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Easy access to individual values from the dictionary\n",
    "print(\"=\" * 70)\n",
    "print(\"EXAMPLE: ACCESSING INDIVIDUAL VALUES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get all alpha values for ADAM ETS Back method\n",
    "method = \"ADAM ETS Back\"\n",
    "print(f\"\\n1. All alpha values for {method}:\")\n",
    "print(f\"   param_results['{method}']['alpha'][:10] = {param_results[method]['alpha'][:10]}\")\n",
    "\n",
    "# Get model types for specific series indices\n",
    "print(f\"\\n2. Model types for first 5 series ({method}):\")\n",
    "for i in range(5):\n",
    "    print(f\"   Series {i}: {param_results[method]['model_types'][i]}\")\n",
    "\n",
    "# Filter by model type\n",
    "print(f\"\\n3. Alpha values for models with trend (containing 'A' or 'M' in position 2):\")\n",
    "model_types = param_results[method]['model_types']\n",
    "alpha_vals = param_results[method]['alpha']\n",
    "trend_mask = [m is not None and len(m) >= 2 and m[1] in ['A', 'M'] for m in model_types]\n",
    "alpha_with_trend = alpha_vals[trend_mask]\n",
    "print(f\"   Count: {len(alpha_with_trend)}, Mean: {np.nanmean(alpha_with_trend):.4f}\")\n",
    "\n",
    "# Compare parameters across methods\n",
    "print(f\"\\n4. Mean alpha across all methods:\")\n",
    "for method in methods_names:\n",
    "    mean_alpha = np.nanmean(param_results[method]['alpha'])\n",
    "    print(f\"   {method}: {mean_alpha:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gkdgofs32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary structure reference\n",
    "print(\"=\" * 70)\n",
    "print(\"PARAM_RESULTS DICTIONARY STRUCTURE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "param_results = {\n",
    "    'ADAM ETS Back': {\n",
    "        'model_types': [...],      # list[str]: Model types (e.g., 'AAN', 'MAdM', 'ANN')\n",
    "        'loss_values': np.array,   # float: Loss function values (CF_value)\n",
    "        'alpha': np.array,         # float: Level smoothing parameter\n",
    "        'beta': np.array,          # float: Trend smoothing parameter (NaN if no trend)\n",
    "        'gamma': np.array,         # float: Seasonal smoothing parameter (NaN if no season)\n",
    "        'phi': np.array,           # float: Dampening parameter (1.0 if not damped)\n",
    "        'errors': [...],           # list[str|None]: Error messages (None if success)\n",
    "    },\n",
    "    'ADAM ETS Opt': { ... },\n",
    "    'ADAM ETS Two': { ... },\n",
    "    'ES Back': { ... },\n",
    "    'ES Opt': { ... },\n",
    "    'ES Two': { ... },\n",
    "}\n",
    "\n",
    "Each array has length = number of datasets (4004 for M1+M3).\n",
    "Access patterns:\n",
    "  - Single value:  param_results['ADAM ETS Back']['alpha'][0]\n",
    "  - All values:    param_results['ADAM ETS Back']['alpha']\n",
    "  - By condition:  param_results['ADAM ETS Back']['alpha'][mask]\n",
    "\"\"\")\n",
    "\n",
    "# Show actual structure\n",
    "print(\"\\nActual keys in param_results:\")\n",
    "print(f\"  Methods: {list(param_results.keys())}\")\n",
    "print(f\"  Per-method keys: {list(param_results[methods_names[0]].keys())}\")\n",
    "print(f\"  Array lengths: {len(param_results[methods_names[0]]['alpha'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (smooth)",
   "language": "python",
   "name": "smooth"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
