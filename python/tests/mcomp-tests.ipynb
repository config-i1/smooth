{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# M-Competition Evaluation\n",
    "\n",
    "This notebook evaluates ADAM and ES models on M1 and M3 competition datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import multiprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from mcomp import M1, M3, load_m1, load_m3\n",
    "from smooth import ADAM, ES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error-metrics-header",
   "metadata": {},
   "source": [
    "## Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "error-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSSE(holdout, forecast, actuals):\n",
    "    \"\"\"\n",
    "    Root Mean Squared Scaled Error.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    holdout : array-like\n",
    "        Actual holdout values\n",
    "    forecast : array-like\n",
    "        Forecasted values\n",
    "    actuals : array-like\n",
    "        In-sample actual values (for scaling)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        RMSSE value\n",
    "    \"\"\"\n",
    "    holdout = np.asarray(holdout)\n",
    "    forecast = np.asarray(forecast)\n",
    "    actuals = np.asarray(actuals)\n",
    "    \n",
    "    mse = np.mean((holdout - forecast) ** 2)\n",
    "    scale = np.mean(np.diff(actuals) ** 2)\n",
    "    \n",
    "    if scale == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return np.sqrt(mse / scale)\n",
    "\n",
    "def SAME(holdout, forecast, actuals):\n",
    "    \"\"\"\n",
    "    Scaled Absolute Mean Error.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    holdout : array-like\n",
    "        Actual holdout values\n",
    "    forecast : array-like\n",
    "        Forecasted values\n",
    "    actuals : array-like\n",
    "        In-sample actual values (for scaling)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        RMSSE value\n",
    "    \"\"\"\n",
    "    holdout = np.asarray(holdout)\n",
    "    forecast = np.asarray(forecast)\n",
    "    actuals = np.asarray(actuals)\n",
    "    \n",
    "    ame = np.abs(np.mean(holdout - forecast))\n",
    "    scale = np.mean(np.abs(np.diff(actuals)))\n",
    "    \n",
    "    if scale == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return ame / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-header",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded M1 dataset: 1001 series\n",
      "Loaded M3 dataset: 3003 series\n",
      "Total series: 4004\n",
      "M1: 1001 series\n",
      "M3: 3003 series\n"
     ]
    }
   ],
   "source": [
    "# Load M1 and M3 datasets\n",
    "m1 = load_m1()\n",
    "m3 = load_m3()\n",
    "\n",
    "# Combine datasets into a list\n",
    "datasets = []\n",
    "for idx in m1.keys():\n",
    "    datasets.append(m1[idx])\n",
    "for idx in m3.keys():\n",
    "    datasets.append(m3[idx])\n",
    "\n",
    "print(f\"Total series: {len(datasets)}\")\n",
    "print(f\"M1: {len(m1)} series\")\n",
    "print(f\"M3: {len(m3)} series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "methods-header",
   "metadata": {},
   "source": [
    "## Define Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "methods-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods: 6\n",
      "Datasets: 4004\n"
     ]
    }
   ],
   "source": [
    "# Method names\n",
    "methods_names = [\n",
    "    \"ADAM ETS Back\",\n",
    "    \"ADAM ETS Opt\", \n",
    "    \"ADAM ETS Two\",\n",
    "    \"ES Back\",\n",
    "    \"ES Opt\",\n",
    "    \"ES Two\"\n",
    "]\n",
    "\n",
    "methods_number = len(methods_names)\n",
    "dataset_length = len(datasets)\n",
    "\n",
    "print(f\"Methods: {methods_number}\")\n",
    "print(f\"Datasets: {dataset_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf4b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   1: B=[0.1000, 0.3000] -> CF=276.506198\n",
      "Iter   2: B=[0.1750, 0.3000] -> CF=270.891794\n",
      "Iter   3: B=[0.1750, 0.5500] -> CF=276.016253\n",
      "Iter   4: B=[0.2500, 0.5500] -> CF=270.874195\n",
      "Iter   5: B=[0.3250, 0.6750] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter   6: B=[0.2500, 0.3000] -> CF=266.342379\n",
      "Iter   7: B=[0.2875, 0.1750] -> CF=262.331859\n",
      "Iter   8: B=[0.3625, 0.4250] -> CF=262.847117\n",
      "Iter   9: B=[0.4000, 0.0500] -> CF=258.143701\n",
      "Iter  10: B=[0.4750, 0.0000] -> CF=267.197279\n",
      "Iter  11: B=[0.3250, 0.0000] -> CF=271.046117\n",
      "Iter  12: B=[0.3531, 0.2688] -> CF=260.744846\n",
      "Iter  13: B=[0.4656, 0.1438] -> CF=254.522530\n",
      "Iter  14: B=[0.5547, 0.1281] -> CF=251.372499\n",
      "Iter  15: B=[0.6016, 0.0000] -> CF=264.469314\n",
      "Iter  16: B=[0.4152, 0.1789] -> CF=256.836429\n",
      "Iter  17: B=[0.5699, 0.2570] -> CF=252.298739\n",
      "Iter  18: B=[0.7094, 0.2063] -> CF=247.434872\n",
      "Iter  19: B=[0.8564, 0.2199] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  20: B=[0.6941, 0.0773] -> CF=247.612994\n",
      "Iter  21: B=[0.8488, 0.1555] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  22: B=[0.6282, 0.1350] -> CF=249.108528\n",
      "Iter  23: B=[0.7753, 0.1486] -> CF=245.220953\n",
      "Iter  24: B=[0.8488, 0.1555] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  25: B=[0.7905, 0.2775] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  26: B=[0.7182, 0.1274] -> CF=246.554102\n",
      "Iter  27: B=[0.7842, 0.0698] -> CF=245.479738\n",
      "Iter  28: B=[0.8412, 0.0910] -> CF=243.734405\n",
      "Iter  29: B=[0.9027, 0.0728] -> CF=242.842730\n",
      "Iter  30: B=[0.8938, 0.1517] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  31: B=[0.8116, 0.0903] -> CF=244.393897\n",
      "Iter  32: B=[0.9390, 0.0144] -> CF=251.738123\n",
      "Iter  33: B=[0.8162, 0.1151] -> CF=244.165891\n",
      "Iter  34: B=[0.9073, 0.0977] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  35: B=[0.8355, 0.0921] -> CF=243.844877\n",
      "Iter  36: B=[0.9220, 0.0498] -> CF=243.671335\n",
      "Iter  37: B=[0.9892, 0.0306] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  38: B=[0.8739, 0.0767] -> CF=243.290615\n",
      "Iter  39: B=[0.8546, 0.0997] -> CF=243.390242\n",
      "Iter  40: B=[0.8715, 0.0872] -> CF=243.159986\n",
      "Iter  41: B=[0.9002, 0.0833] -> CF=242.672895\n",
      "Iter  42: B=[0.9134, 0.0867] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  43: B=[0.9315, 0.0689] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  44: B=[0.8865, 0.0827] -> CF=242.936284\n",
      "Iter  45: B=[0.9165, 0.0735] -> CF=242.582629\n",
      "Iter  46: B=[0.9315, 0.0689] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  47: B=[0.9140, 0.0840] -> CF=242.422422\n",
      "Iter  48: B=[0.9197, 0.0896] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  49: B=[0.9302, 0.0742] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  50: B=[0.9077, 0.0811] -> CF=242.576180\n",
      "Iter  51: B=[0.9053, 0.0916] -> CF=242.489638\n",
      "Iter  52: B=[0.9115, 0.0945] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  53: B=[0.9087, 0.0844] -> CF=242.508307\n",
      "Iter  54: B=[0.9106, 0.0912] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  55: B=[0.9092, 0.0861] -> CF=242.478223\n",
      "Iter  56: B=[0.9179, 0.0786] -> CF=242.446039\n",
      "Iter  57: B=[0.9227, 0.0765] -> CF=242.407160\n",
      "Iter  58: B=[0.9295, 0.0717] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  59: B=[0.9188, 0.0819] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  60: B=[0.9181, 0.0794] -> CF=242.426259\n",
      "Iter  61: B=[0.9186, 0.0811] -> CF=242.388989\n",
      "Iter  62: B=[0.9188, 0.0819] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  63: B=[0.9273, 0.0736] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  64: B=[0.9173, 0.0814] -> CF=242.405279\n",
      "Iter  65: B=[0.9132, 0.0860] -> CF=242.409901\n",
      "Iter  66: B=[0.9204, 0.0789] -> CF=242.398983\n",
      "Iter  67: B=[0.9216, 0.0786] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  68: B=[0.9184, 0.0807] -> CF=242.399034\n",
      "Iter  69: B=[0.9206, 0.0793] -> CF=242.388208\n",
      "Iter  70: B=[0.9216, 0.0786] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  71: B=[0.9188, 0.0815] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  72: B=[0.9200, 0.0795] -> CF=242.393343\n",
      "Iter  73: B=[0.9192, 0.0808] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  74: B=[0.9198, 0.0799] -> CF=242.390695\n",
      "Iter  75: B=[0.9194, 0.0805] -> CF=242.385735\n",
      "Iter  76: B=[0.9192, 0.0808] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  77: B=[0.9213, 0.0787] -> CF=10000000000000000159028911097599180468360808563945281389781327557747838772170381060813469985856815104.000000\n",
      "Iter  78: B=[0.9193, 0.0805] -> CF=242.387688\n",
      "Iter  79: B=[0.9181, 0.0817] -> CF=242.386784\n",
      "Iter  80: B=[0.9182, 0.0818] -> CF=242.384848\n",
      "Time elapsed: 0.04 seconds\n",
      "Model estimated using ADAM() function: ETS(ANA)\n",
      "With backcasting initialisation\n",
      "Distribution assumed in the model: Normal\n",
      "Loss function type: likelihood; Loss function value: 242.3848\n",
      "Persistence vector g:\n",
      " alpha  gamma\n",
      "0.9182 0.0818\n",
      "Sample size: 89\n",
      "Number of estimated parameters: 3\n",
      "Number of degrees of freedom: 86\n",
      "Information criteria:\n",
      "      AIC      AICc       BIC      BICc\n",
      " 490.7697  491.0520  498.2356  498.8693\n"
     ]
    }
   ],
   "source": [
    "series = datasets[384+16]\n",
    "# series = datasets[2568+1000]\n",
    "\n",
    "# print(series.x)\n",
    "# from smooth import msdecompose\n",
    "\n",
    "# modelM = msdecompose(series.x, type=\"additive\", smoother=\"ma\")\n",
    "\n",
    "# print(modelM)\n",
    "\n",
    "# Fit model\n",
    "model = ADAM(model=\"ANA\", lags=[1, series.period], initial=\"backcasting\",\n",
    "                nlopt_kargs={\n",
    "                    \"print_level\": 1,        # Print optimization progress\n",
    "                    \"maxeval\": 1,\n",
    "                })\n",
    "model.fit(series.x)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92901cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-functions-header",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "evaluation-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_single_series(series, method_name):\n",
    "    \"\"\"\n",
    "    Evaluate a single method on a single series.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series : MCompSeries\n",
    "        Series to evaluate\n",
    "    method_name : str\n",
    "        Name of the method to use\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (RMSSE, SAME, time_elapsed)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Determine lags and model based on period\n",
    "        period = series.period\n",
    "        if period > 1:\n",
    "            lags = [1, period]\n",
    "            model_str = \"ZXZ\"  # Auto-select including seasonality\n",
    "        else:\n",
    "            lags = [1]\n",
    "            model_str = \"ZXN\"  # Auto-select without seasonality for non-seasonal data\n",
    "        \n",
    "        # Select model class based on method\n",
    "        if \"ADAM\" in method_name:\n",
    "            model_class = ADAM\n",
    "        else:\n",
    "            model_class = ES\n",
    "        \n",
    "        if \"Back\" in method_name:\n",
    "            initial = \"backcasting\"\n",
    "        elif \"Opt\" in method_name:\n",
    "            initial = \"optimal\"\n",
    "        elif \"Two\" in method_name:\n",
    "            initial = \"two-stage\"\n",
    "        else:\n",
    "            initial = \"backcasting\"\n",
    "        \n",
    "        # Create and fit model\n",
    "        model = model_class(model=model_str, lags=lags, initial=initial)\n",
    "        model.fit(series.x)\n",
    "        \n",
    "        # Generate forecasts\n",
    "        forecasts = model.predict(h=series.h)\n",
    "        forecast_values = forecasts['mean'].values\n",
    "        \n",
    "        time_elapsed = time.time() - start_time\n",
    "        \n",
    "        # Calculate RMSSE\n",
    "        rmsse = RMSSE(series.xx, forecast_values, series.x)\n",
    "        same = SAME(series.xx, forecast_values, series.x)\n",
    "        \n",
    "        return (rmsse, same, time_elapsed)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "\n",
    "\n",
    "def evaluate_method_sequential(datasets, method_name, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a method on all datasets sequentially.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datasets : list\n",
    "        List of MCompSeries\n",
    "    method_name : str\n",
    "        Name of the method\n",
    "    verbose : bool\n",
    "        Whether to print progress\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Arrays of (RMSSE values, time values)\n",
    "    \"\"\"\n",
    "    n = len(datasets)\n",
    "    rmsse_values = np.full(n, np.nan)\n",
    "    same_values = np.full(n, np.nan)\n",
    "    time_values = np.full(n, np.nan)\n",
    "    \n",
    "    for i, series in enumerate(datasets):\n",
    "        if verbose and (i + 1) % 100 == 0:\n",
    "            print(f\"  {method_name}: {i + 1}/{n}\")\n",
    "        \n",
    "        rmsse, same, elapsed = evaluate_single_series(series, method_name)\n",
    "        rmsse_values[i] = rmsse\n",
    "        same_values[i] = same\n",
    "        time_values[i] = elapsed\n",
    "    \n",
    "    return rmsse_values, same_values, time_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "en8djiptws7",
   "metadata": {},
   "source": [
    "## Parallel Evaluation\n",
    "\n",
    "Run evaluation using all CPU cores for faster processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "y8zr0q53z4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_task(args):\n",
    "    \"\"\"\n",
    "    Worker function for parallel evaluation.\n",
    "    Must be defined at module level for pickling.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args : tuple\n",
    "        (series_idx, series_data, method_name) where series_data is a dict\n",
    "        containing the series attributes needed for evaluation\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (series_idx, method_name, rmsse, same, time_elapsed)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import time\n",
    "    from smooth import ADAM, ES\n",
    "    \n",
    "    series_idx, series_data, method_name = args\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Reconstruct series data\n",
    "        x = series_data['x']\n",
    "        xx = series_data['xx']\n",
    "        h = series_data['h']\n",
    "        period = series_data['period']\n",
    "        \n",
    "        # Determine lags and model based on period\n",
    "        if period > 1:\n",
    "            lags = [1, period]\n",
    "            model_str = \"ZXZ\"\n",
    "        else:\n",
    "            lags = [1]\n",
    "            model_str = \"ZXN\"\n",
    "        \n",
    "        # Select model class based on method\n",
    "        if \"ADAM\" in method_name:\n",
    "            model_class = ADAM\n",
    "        else:\n",
    "            model_class = ES\n",
    "        \n",
    "        if \"Back\" in method_name:\n",
    "            initial = \"backcasting\"\n",
    "        elif \"Opt\" in method_name:\n",
    "            initial = \"optimal\"\n",
    "        elif \"Two\" in method_name:\n",
    "            initial = \"two-stage\"\n",
    "        else:\n",
    "            initial = \"backcasting\"\n",
    "        \n",
    "        # Create and fit model\n",
    "        model = model_class(model=model_str, lags=lags, initial=initial)\n",
    "        model.fit(x)\n",
    "        \n",
    "        # Generate forecasts\n",
    "        forecasts = model.predict(h=h)\n",
    "        forecast_values = forecasts['mean'].values\n",
    "        \n",
    "        time_elapsed = time.time() - start_time\n",
    "        \n",
    "        # Calculate metrics\n",
    "        holdout = np.asarray(xx)\n",
    "        actuals = np.asarray(x)\n",
    "        \n",
    "        # RMSSE\n",
    "        mse = np.mean((holdout - forecast_values) ** 2)\n",
    "        scale = np.mean(np.diff(actuals) ** 2)\n",
    "        rmsse = np.sqrt(mse / scale) if scale != 0 else np.nan\n",
    "        \n",
    "        # SAME\n",
    "        ame = np.abs(np.mean(holdout - forecast_values))\n",
    "        scale_same = np.mean(np.abs(np.diff(actuals)))\n",
    "        same = ame / scale_same if scale_same != 0 else np.nan\n",
    "        \n",
    "        return (series_idx, method_name, rmsse, same, time_elapsed)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return (series_idx, method_name, np.nan, np.nan, np.nan)\n",
    "\n",
    "\n",
    "def evaluate_parallel(datasets, methods_names, n_workers=None):\n",
    "    \"\"\"\n",
    "    Evaluate all methods on all datasets in parallel.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datasets : list\n",
    "        List of MCompSeries objects\n",
    "    methods_names : list\n",
    "        List of method names to evaluate\n",
    "    n_workers : int, optional\n",
    "        Number of parallel workers. Defaults to all CPU cores.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Results array of shape (n_methods, n_datasets, 3) containing\n",
    "        [RMSSE, SAME, time] for each method-dataset combination\n",
    "    \"\"\"\n",
    "    if n_workers is None:\n",
    "        n_workers = multiprocessing.cpu_count()\n",
    "    \n",
    "    n_methods = len(methods_names)\n",
    "    n_datasets = len(datasets)\n",
    "    \n",
    "    # Initialize results array\n",
    "    results = np.full((n_methods, n_datasets, 3), np.nan)\n",
    "    \n",
    "    # Prepare tasks: convert series to picklable dicts\n",
    "    tasks = []\n",
    "    for j, method_name in enumerate(methods_names):\n",
    "        for i, series in enumerate(datasets):\n",
    "            series_data = {\n",
    "                'x': np.asarray(series.x),\n",
    "                'xx': np.asarray(series.xx),\n",
    "                'h': series.h,\n",
    "                'period': series.period\n",
    "            }\n",
    "            tasks.append((i, series_data, method_name))\n",
    "    \n",
    "    print(f\"Starting parallel evaluation with {n_workers} workers...\")\n",
    "    print(f\"Total tasks: {len(tasks)} ({n_methods} methods × {n_datasets} series)\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    completed = 0\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "        futures = {executor.submit(_evaluate_task, task): task for task in tasks}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            result = future.result()\n",
    "            series_idx, method_name, rmsse, same, elapsed = result\n",
    "            \n",
    "            # Find method index\n",
    "            method_idx = methods_names.index(method_name)\n",
    "            \n",
    "            # Store results\n",
    "            results[method_idx, series_idx, 0] = rmsse\n",
    "            results[method_idx, series_idx, 1] = same\n",
    "            results[method_idx, series_idx, 2] = elapsed\n",
    "            \n",
    "            completed += 1\n",
    "            if completed % 1000 == 0:\n",
    "                elapsed_total = time.time() - start_time\n",
    "                rate = completed / elapsed_total\n",
    "                remaining = (len(tasks) - completed) / rate\n",
    "                print(f\"  Progress: {completed}/{len(tasks)} ({100*completed/len(tasks):.1f}%) - \"\n",
    "                      f\"ETA: {remaining/60:.1f} min\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nCompleted in {total_time/60:.1f} minutes ({total_time:.1f}s)\")\n",
    "    print(f\"Average time per task: {total_time/len(tasks)*1000:.1f}ms\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "swpfq4ermj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPU cores: 32\n",
      "Starting parallel evaluation with 32 workers...\n",
      "Total tasks: 24024 (6 methods × 4004 series)\n",
      "  Progress: 1000/24024 (4.2%) - ETA: 3.5 min\n",
      "  Progress: 2000/24024 (8.3%) - ETA: 2.4 min\n",
      "  Progress: 3000/24024 (12.5%) - ETA: 2.6 min\n",
      "  Progress: 4000/24024 (16.7%) - ETA: 2.7 min\n",
      "  Progress: 5000/24024 (20.8%) - ETA: 3.2 min\n",
      "  Progress: 6000/24024 (25.0%) - ETA: 2.9 min\n",
      "  Progress: 7000/24024 (29.1%) - ETA: 3.0 min\n",
      "  Progress: 8000/24024 (33.3%) - ETA: 3.2 min\n",
      "  Progress: 9000/24024 (37.5%) - ETA: 3.3 min\n",
      "  Progress: 10000/24024 (41.6%) - ETA: 3.0 min\n",
      "  Progress: 11000/24024 (45.8%) - ETA: 2.9 min\n",
      "  Progress: 12000/24024 (50.0%) - ETA: 2.9 min\n",
      "  Progress: 13000/24024 (54.1%) - ETA: 2.6 min\n",
      "  Progress: 14000/24024 (58.3%) - ETA: 2.2 min\n",
      "  Progress: 15000/24024 (62.4%) - ETA: 2.0 min\n",
      "  Progress: 16000/24024 (66.6%) - ETA: 1.7 min\n",
      "  Progress: 17000/24024 (70.8%) - ETA: 1.5 min\n",
      "  Progress: 18000/24024 (74.9%) - ETA: 1.3 min\n",
      "  Progress: 19000/24024 (79.1%) - ETA: 1.1 min\n",
      "  Progress: 20000/24024 (83.3%) - ETA: 0.9 min\n",
      "  Progress: 21000/24024 (87.4%) - ETA: 0.7 min\n",
      "  Progress: 22000/24024 (91.6%) - ETA: 0.5 min\n",
      "  Progress: 23000/24024 (95.7%) - ETA: 0.2 min\n",
      "  Progress: 24000/24024 (99.9%) - ETA: 0.0 min\n",
      "\n",
      "Completed in 5.8 minutes (346.4s)\n",
      "Average time per task: 14.4ms\n",
      "\n",
      "Per-method summary:\n",
      "  ADAM ETS Back: RMSSE=2.0742, SAME=2.0878, Time=0.249s, Failed=0\n",
      "  ADAM ETS Opt: RMSSE=2.0890, SAME=2.1017, Time=0.503s, Failed=0\n",
      "  ADAM ETS Two: RMSSE=2.0982, SAME=2.1123, Time=0.641s, Failed=0\n",
      "  ES Back: RMSSE=2.0740, SAME=2.0865, Time=0.250s, Failed=0\n",
      "  ES Opt: RMSSE=2.0932, SAME=2.1075, Time=0.493s, Failed=0\n",
      "  ES Two: RMSSE=2.1116, SAME=2.1306, Time=0.622s, Failed=0\n"
     ]
    }
   ],
   "source": [
    "# Run parallel evaluation using all CPU cores\n",
    "# This is much faster than sequential evaluation\n",
    "\n",
    "print(f\"Available CPU cores: {multiprocessing.cpu_count()}\")\n",
    "\n",
    "# Run parallel evaluation\n",
    "test_results = evaluate_parallel(datasets, methods_names)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nPer-method summary:\")\n",
    "for j, method in enumerate(methods_names):\n",
    "    rmsse_mean = np.nanmean(test_results[j, :, 0])\n",
    "    same_mean = np.nanmean(test_results[j, :, 1])\n",
    "    time_mean = np.nanmean(test_results[j, :, 2])\n",
    "    failed = np.sum(np.isnan(test_results[j, :, 0]))\n",
    "    print(f\"  {method}: RMSSE={rmsse_mean:.4f}, SAME={same_mean:.4f}, \"\n",
    "          f\"Time={time_mean:.3f}s, Failed={failed}\")\n",
    "\n",
    "np.save('2026-01-18-Mcomp-test.npy', test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-header",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "summarize-results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "       Method      Min       Q1      Med       Q3       Max     Mean  Mean Time (s)  Failed\n",
      "ADAM ETS Back 0.018252 0.702559 1.236860 2.502872 50.258736 2.074190       0.249316       0\n",
      " ADAM ETS Opt 0.024155 0.704957 1.271720 2.547423 51.616184 2.088998       0.502655       0\n",
      " ADAM ETS Two 0.024925 0.706665 1.270696 2.522547 51.616184 2.098152       0.640548       0\n",
      "      ES Back 0.018252 0.703143 1.237069 2.512100 50.258736 2.074022       0.249799       0\n",
      "       ES Opt 0.024155 0.701496 1.270929 2.537751 51.616184 2.093215       0.492826       0\n",
      "       ES Two 0.024925 0.706814 1.274917 2.557509 51.616184 2.111611       0.621837       0\n"
     ]
    }
   ],
   "source": [
    "test_results = np.load('2026-01-18-Mcomp-test.npy')\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'Method': methods_names,\n",
    "    'Min': [np.nanmin(test_results[j, :, 0]) for j in range(methods_number)],\n",
    "    'Q1': [np.nanquantile(test_results[j, :, 0], 0.25) for j in range(methods_number)],\n",
    "    'Med': [np.nanmedian(test_results[j, :, 0]) for j in range(methods_number)],\n",
    "    'Q3': [np.nanquantile(test_results[j, :, 0], 0.75) for j in range(methods_number)],\n",
    "    'Max': [np.nanmax(test_results[j, :, 0]) for j in range(methods_number)],\n",
    "    'Mean': [np.nanmean(test_results[j, :, 0]) for j in range(methods_number)],\n",
    "    # 'Mean SAME': [np.nanmean(test_results[j, :, 1]) for j in range(methods_number)],\n",
    "    # 'Med SAME': [np.nanmedian(test_results[j, :, 1]) for j in range(methods_number)],\n",
    "    'Mean Time (s)': [np.nanmean(test_results[j, :, 2]) for j in range(methods_number)],\n",
    "    'Failed': [np.sum(np.isnan(test_results[j, :, 0])) for j in range(methods_number)]\n",
    "})\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-by-type",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results by series type\n",
    "series_types = [s.type for s in datasets]\n",
    "unique_types = list(set(series_types))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS BY SERIES TYPE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for stype in unique_types:\n",
    "    mask = np.array([s.type == stype for s in datasets])\n",
    "    print(f\"\\n{stype.upper()} ({np.sum(mask)} series):\")\n",
    "    \n",
    "    for j, method in enumerate(methods_names):\n",
    "        rmsse_type = test_results[j, mask, 0]\n",
    "        print(f\"  {method}: Mean RMSSE = {np.nanmean(rmsse_type):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import datetime\n",
    "import joblib\n",
    "\n",
    "date_str = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Save as numpy array\n",
    "np.save(f'test_results_{date_str}.npy', test_results)\n",
    "\n",
    "# Save summary as CSV\n",
    "summary.to_csv(f'test_summary_{date_str}.csv', index=False)\n",
    "\n",
    "# Save complete results with metadata using joblib\n",
    "results_dict = {\n",
    "    'test_results': test_results,\n",
    "    'methods_names': methods_names,\n",
    "    'dataset_info': [(s.sn, s.type, s.period, len(s.x), s.h) for s in datasets],\n",
    "    'summary': summary\n",
    "}\n",
    "joblib.dump(results_dict, f'test_results_full_{date_str}.joblib')\n",
    "\n",
    "print(f\"Results saved:\")\n",
    "print(f\"  - test_results_{date_str}.npy (raw array)\")\n",
    "print(f\"  - test_summary_{date_str}.csv (summary table)\")\n",
    "print(f\"  - test_results_full_{date_str}.joblib (complete with metadata)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-series-header",
   "metadata": {},
   "source": [
    "## Single Series Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52aeb09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.13 5.16 5.17 5.2  5.22 5.2  5.24 5.26 5.27 5.3  5.32 5.34 5.39 5.43\n",
      " 5.45 5.49 5.54 5.57 5.59 5.59 5.58 5.54 5.53 5.54 5.54 5.56 5.6  5.6\n",
      " 5.6  5.59 5.57 5.53 5.5  5.48 5.44 5.45 5.49 5.54 5.58 5.63 5.68 5.69\n",
      " 5.71 5.72 5.73 5.74 5.77 5.79 5.78 5.78 5.81 5.83 5.86 5.9  5.91 5.94]\n",
      "Time elapsed: 0.02 seconds\n",
      "Model estimated using ES() function: ETS(AAdN)\n",
      "With backcasting initialisation\n",
      "Distribution assumed in the model: Normal\n",
      "Loss function type: likelihood; Loss function value: -138.2533\n",
      "Persistence vector g:\n",
      " alpha   beta\n",
      "1.0000 0.6923\n",
      "Damping parameter: 1.0000\n",
      "Sample size: 56\n",
      "Number of estimated parameters: 4\n",
      "Number of degrees of freedom: 52\n",
      "Information criteria:\n",
      "      AIC      AICc       BIC      BICc\n",
      "-268.5066 -267.7222 -260.4052 -258.8266\n"
     ]
    }
   ],
   "source": [
    "series = datasets[349]\n",
    "print(series.x)\n",
    "\n",
    "# Fit model\n",
    "model = ES(model=\"AAdN\", lags=[1, series.period], initial=\"backcasting\")\n",
    "model.fit(series.x)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-series-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a single series to see detailed output\n",
    "series = M3[203]\n",
    "print(f\"Series: {series}\")\n",
    "print(f\"Training length: {len(series.x)}\")\n",
    "print(f\"Test length: {len(series.xx)}\")\n",
    "print(f\"Period: {series.period}\")\n",
    "\n",
    "# Fit model\n",
    "model = ES(model=\"ZXZ\", lags=[1, series.period], initial=\"optimal\")\n",
    "model.fit(series.x)\n",
    "\n",
    "print(\"\\n\" + str(model))\n",
    "\n",
    "# Forecast\n",
    "forecasts = model.predict(h=series.h)\n",
    "print(\"\\nForecasts vs Actuals:\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Forecast': forecasts['mean'].values,\n",
    "    'Actual': series.xx,\n",
    "    'Error': forecasts['mean'].values - series.xx\n",
    "})\n",
    "print(comparison)\n",
    "\n",
    "# Calculate error metrics\n",
    "rmsse = RMSSE(series.xx, forecasts['mean'].values, series.x)\n",
    "print(f\"\\nRMSSE: {rmsse:.4f}\")\n",
    "\n",
    "same = SAME(series.xx, forecasts['mean'].values, series.x)\n",
    "print(f\"\\nSAME: {same:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kobeicx8348",
   "metadata": {},
   "source": [
    "## Parameter Distribution Analysis\n",
    "\n",
    "Record model types, loss values, smoothing and dampening parameters for distribution analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "j16fmq1bsoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_params_task(args):\n",
    "    \"\"\"\n",
    "    Worker function for parallel parameter extraction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args : tuple\n",
    "        (series_idx, series_data, method_name)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (series_idx, method_name, params_dict)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import time\n",
    "    from smooth import ADAM, ES\n",
    "    \n",
    "    series_idx, series_data, method_name = args\n",
    "    \n",
    "    # Initialize result dict with NaN/None defaults\n",
    "    params = {\n",
    "        'model_type': None,\n",
    "        'loss_value': np.nan,\n",
    "        'alpha': np.nan,\n",
    "        'beta': np.nan,\n",
    "        'gamma': np.nan,\n",
    "        'phi': np.nan,\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Reconstruct series data\n",
    "        x = series_data['x']\n",
    "        period = series_data['period']\n",
    "        \n",
    "        # Determine lags and model based on period\n",
    "        if period > 1:\n",
    "            lags = [1, period]\n",
    "            model_str = \"ZXZ\"\n",
    "        else:\n",
    "            lags = [1]\n",
    "            model_str = \"ZXN\"\n",
    "        \n",
    "        # Select model class based on method\n",
    "        if \"ADAM\" in method_name:\n",
    "            model_class = ADAM\n",
    "        else:\n",
    "            model_class = ES\n",
    "        \n",
    "        if \"Back\" in method_name:\n",
    "            initial = \"backcasting\"\n",
    "        elif \"Opt\" in method_name:\n",
    "            initial = \"optimal\"\n",
    "        elif \"Two\" in method_name:\n",
    "            initial = \"two-stage\"\n",
    "        else:\n",
    "            initial = \"backcasting\"\n",
    "        \n",
    "        # Create and fit model\n",
    "        model = model_class(model=model_str, lags=lags, initial=initial)\n",
    "        model.fit(x)\n",
    "        \n",
    "        # Extract the SELECTED model type (not the input model string)\n",
    "        # Construct from error_type, trend_type, season_type, and damped flag\n",
    "        if hasattr(model, 'model_type_dict') and model.model_type_dict:\n",
    "            error_type = model.model_type_dict.get('error_type', '')\n",
    "            trend_type = model.model_type_dict.get('trend_type', '')\n",
    "            season_type = model.model_type_dict.get('season_type', '')\n",
    "            damped = model.model_type_dict.get('damped', False)\n",
    "            \n",
    "            # Construct model string: e.g., \"MAN\", \"AAdA\", \"ANN\"\n",
    "            if error_type and trend_type is not None and season_type is not None:\n",
    "                selected_model = error_type + trend_type\n",
    "                if damped and trend_type != 'N':\n",
    "                    selected_model += 'd'\n",
    "                selected_model += season_type\n",
    "                params['model_type'] = selected_model\n",
    "        \n",
    "        # Extract loss value\n",
    "        if hasattr(model, 'adam_estimated') and model.adam_estimated:\n",
    "            params['loss_value'] = model.adam_estimated.get('CF_value', np.nan)\n",
    "        \n",
    "        # Extract smoothing parameters\n",
    "        if hasattr(model, 'persistence_level_') and model.persistence_level_ is not None:\n",
    "            params['alpha'] = float(model.persistence_level_)\n",
    "        \n",
    "        if hasattr(model, 'persistence_trend_') and model.persistence_trend_ is not None:\n",
    "            params['beta'] = float(model.persistence_trend_)\n",
    "        \n",
    "        if hasattr(model, 'persistence_seasonal_') and model.persistence_seasonal_ is not None:\n",
    "            gamma = model.persistence_seasonal_\n",
    "            if isinstance(gamma, (list, np.ndarray)) and len(gamma) > 0:\n",
    "                params['gamma'] = float(gamma[0])\n",
    "            elif isinstance(gamma, (int, float)):\n",
    "                params['gamma'] = float(gamma)\n",
    "        \n",
    "        # Extract dampening parameter\n",
    "        if hasattr(model, 'phi_') and model.phi_ is not None:\n",
    "            params['phi'] = float(model.phi_)\n",
    "        \n",
    "        return (series_idx, method_name, params)\n",
    "    \n",
    "    except Exception as e:\n",
    "        params['error'] = str(e)\n",
    "        return (series_idx, method_name, params)\n",
    "\n",
    "\n",
    "def extract_params_parallel(datasets, methods_names, n_workers=None):\n",
    "    \"\"\"\n",
    "    Extract model parameters for all methods on all datasets in parallel.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datasets : list\n",
    "        List of MCompSeries objects\n",
    "    methods_names : list\n",
    "        List of method names to evaluate\n",
    "    n_workers : int, optional\n",
    "        Number of parallel workers. Defaults to all CPU cores.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Nested dictionary with structure:\n",
    "        {\n",
    "            method_name: {\n",
    "                'model_types': [...],      # list of selected model types (e.g., 'AAN', 'MAdM')\n",
    "                'loss_values': [...],      # list of loss values\n",
    "                'alpha': [...],            # list of alpha (level smoothing) values\n",
    "                'beta': [...],             # list of beta (trend smoothing) values\n",
    "                'gamma': [...],            # list of gamma (seasonal smoothing) values\n",
    "                'phi': [...],              # list of phi (dampening) values\n",
    "                'errors': [...],           # list of error messages (None if success)\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    if n_workers is None:\n",
    "        n_workers = multiprocessing.cpu_count()\n",
    "    \n",
    "    n_methods = len(methods_names)\n",
    "    n_datasets = len(datasets)\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        method: {\n",
    "            'model_types': [None] * n_datasets,\n",
    "            'loss_values': [np.nan] * n_datasets,\n",
    "            'alpha': [np.nan] * n_datasets,\n",
    "            'beta': [np.nan] * n_datasets,\n",
    "            'gamma': [np.nan] * n_datasets,\n",
    "            'phi': [np.nan] * n_datasets,\n",
    "            'errors': [None] * n_datasets,\n",
    "        }\n",
    "        for method in methods_names\n",
    "    }\n",
    "    \n",
    "    # Prepare tasks\n",
    "    tasks = []\n",
    "    for method_name in methods_names:\n",
    "        for i, series in enumerate(datasets):\n",
    "            series_data = {\n",
    "                'x': np.asarray(series.x),\n",
    "                'period': series.period\n",
    "            }\n",
    "            tasks.append((i, series_data, method_name))\n",
    "    \n",
    "    print(f\"Starting parallel parameter extraction with {n_workers} workers...\")\n",
    "    print(f\"Total tasks: {len(tasks)} ({n_methods} methods × {n_datasets} series)\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    completed = 0\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "        futures = {executor.submit(_extract_params_task, task): task for task in tasks}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            series_idx, method_name, params = future.result()\n",
    "            \n",
    "            # Store results\n",
    "            results[method_name]['model_types'][series_idx] = params['model_type']\n",
    "            results[method_name]['loss_values'][series_idx] = params['loss_value']\n",
    "            results[method_name]['alpha'][series_idx] = params['alpha']\n",
    "            results[method_name]['beta'][series_idx] = params['beta']\n",
    "            results[method_name]['gamma'][series_idx] = params['gamma']\n",
    "            results[method_name]['phi'][series_idx] = params['phi']\n",
    "            results[method_name]['errors'][series_idx] = params['error']\n",
    "            \n",
    "            completed += 1\n",
    "            if completed % 1000 == 0:\n",
    "                elapsed_total = time.time() - start_time\n",
    "                rate = completed / elapsed_total\n",
    "                remaining = (len(tasks) - completed) / rate\n",
    "                print(f\"  Progress: {completed}/{len(tasks)} ({100*completed/len(tasks):.1f}%) - \"\n",
    "                      f\"ETA: {remaining/60:.1f} min\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nCompleted in {total_time/60:.1f} minutes ({total_time:.1f}s)\")\n",
    "    \n",
    "    # Convert lists to numpy arrays for easier analysis\n",
    "    for method in methods_names:\n",
    "        results[method]['loss_values'] = np.array(results[method]['loss_values'])\n",
    "        results[method]['alpha'] = np.array(results[method]['alpha'])\n",
    "        results[method]['beta'] = np.array(results[method]['beta'])\n",
    "        results[method]['gamma'] = np.array(results[method]['gamma'])\n",
    "        results[method]['phi'] = np.array(results[method]['phi'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8qovle0mmze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parallel parameter extraction with 32 workers...\n",
      "Total tasks: 24024 (6 methods × 4004 series)\n",
      "  Progress: 1000/24024 (4.2%) - ETA: 18.2 min\n",
      "  Progress: 2000/24024 (8.3%) - ETA: 12.4 min\n",
      "  Progress: 3000/24024 (12.5%) - ETA: 14.6 min\n",
      "  Progress: 4000/24024 (16.7%) - ETA: 15.9 min\n",
      "  Progress: 5000/24024 (20.8%) - ETA: 20.3 min\n",
      "  Progress: 6000/24024 (25.0%) - ETA: 18.2 min\n",
      "  Progress: 7000/24024 (29.1%) - ETA: 20.8 min\n",
      "  Progress: 8000/24024 (33.3%) - ETA: 22.8 min\n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "  Progress: 9000/24024 (37.5%) - ETA: 22.7 min\n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "  Progress: 10000/24024 (41.6%) - ETA: 20.2 min\n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "  Progress: 11000/24024 (45.8%) - ETA: 20.1 min\n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "  Progress: 12000/24024 (50.0%) - ETA: 20.0 min\n",
      "Optimization error: \n",
      "  Progress: 13000/24024 (54.1%) - ETA: 17.6 min\n",
      "  Progress: 14000/24024 (58.3%) - ETA: 15.1 min\n",
      "  Progress: 15000/24024 (62.4%) - ETA: 13.3 min\n",
      "  Progress: 16000/24024 (66.6%) - ETA: 11.6 min\n",
      "  Progress: 17000/24024 (70.8%) - ETA: 10.4 min\n",
      "  Progress: 18000/24024 (74.9%) - ETA: 8.7 min\n",
      "  Progress: 19000/24024 (79.1%) - ETA: 7.5 min\n",
      "  Progress: 20000/24024 (83.3%) - ETA: 6.3 min\n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "  Progress: 21000/24024 (87.4%) - ETA: 4.8 min\n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "  Progress: 22000/24024 (91.6%) - ETA: 3.1 min\n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "  Progress: 23000/24024 (95.7%) - ETA: 1.6 min\n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "Optimization error: \n",
      "  Progress: 24000/24024 (99.9%) - ETA: 0.0 min\n",
      "\n",
      "Completed in 39.4 minutes (2363.4s)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'joblib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2026-01-19-Mcomp-param_results.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, param_results)\n",
      "\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n",
      "\u001b[0;32m----> 7\u001b[0m \u001b[43mjoblib\u001b[49m\u001b[38;5;241m.\u001b[39mdump(param_results, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2026-01-19-Mcomp-params.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter results saved to 2026-01-19-Mcomp-params.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'joblib' is not defined"
     ]
    }
   ],
   "source": [
    "# Run parallel parameter extraction\n",
    "param_results = extract_params_parallel(datasets, methods_names)\n",
    "\n",
    "np.save('2026-01-19-Mcomp-param_results.npy', param_results)\n",
    "\n",
    "# Save results\n",
    "joblib.dump(param_results, '2026-01-19-Mcomp-params.joblib')\n",
    "print(\"Parameter results saved to 2026-01-19-Mcomp-params.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "qpb72pctj8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL TYPE DISTRIBUTION BY METHOD\n",
      "======================================================================\n",
      "\n",
      "ADAM ETS Back:\n",
      "MAN    509\n",
      "MAA    374\n",
      "MMM    321\n",
      "MNM    289\n",
      "MMN    288\n",
      "AAN    248\n",
      "MNN    218\n",
      "ANN    205\n",
      "ANA    196\n",
      "MAM    192\n",
      "\n",
      "ADAM ETS Opt:\n",
      "MNN     537\n",
      "ANN     469\n",
      "MAN     450\n",
      "MMN     319\n",
      "MAM     241\n",
      "MMdN    221\n",
      "MNA     216\n",
      "AAN     210\n",
      "AMN     155\n",
      "MNM     149\n",
      "\n",
      "ADAM ETS Two:\n",
      "MNN     537\n",
      "ANN     469\n",
      "MAN     450\n",
      "MMN     319\n",
      "MAM     241\n",
      "MMdN    221\n",
      "MNA     216\n",
      "AAN     210\n",
      "AMN     155\n",
      "MNM     149\n",
      "\n",
      "ES Back:\n",
      "MAN    494\n",
      "MAA    356\n",
      "MMM    303\n",
      "MNM    301\n",
      "MMN    298\n",
      "AAN    259\n",
      "ANN    221\n",
      "MAM    208\n",
      "ANA    204\n",
      "MNN    198\n",
      "\n",
      "ES Opt:\n",
      "MNN     559\n",
      "ANN     458\n",
      "MAN     450\n",
      "MMN     328\n",
      "MAM     235\n",
      "MMdN    224\n",
      "MNA     221\n",
      "AAN     206\n",
      "MNM     192\n",
      "AMN     145\n",
      "\n",
      "ES Two:\n",
      "MNN     559\n",
      "ANN     458\n",
      "MAN     450\n",
      "MMN     328\n",
      "MAM     235\n",
      "MMdN    224\n",
      "MNA     221\n",
      "AAN     206\n",
      "MNM     192\n",
      "AMN     145\n"
     ]
    }
   ],
   "source": [
    "# param_results = np.load('2026-01-19-Mcomp-param_results.npy')\n",
    "\n",
    "# Analyze model type distributions\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL TYPE DISTRIBUTION BY METHOD\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for method in methods_names:\n",
    "    model_types = param_results[method]['model_types']\n",
    "    # Count occurrences of each model type\n",
    "    type_counts = pd.Series(model_types).value_counts()\n",
    "    print(f\"\\n{method}:\")\n",
    "    print(type_counts.head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dewllxjgw84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PARAMETER DISTRIBUTION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "ADAM ETS Back:\n",
      "------------------------------------------------------------\n",
      "    Parameter  Count     Mean      Std       Min      Q25   Median      Q75       Max  Where\n",
      "Phi (damping)     44   0.8153   0.2004    0.2613   0.6990   0.8945   0.9543    1.0000      1\n",
      "   Loss value   4004 399.0250 279.3171 -349.9066 168.9460 321.3418 600.6941 1401.8902    474\n",
      "\n",
      "ADAM ETS Opt:\n",
      "------------------------------------------------------------\n",
      "    Parameter  Count     Mean      Std       Min      Q25   Median      Q75       Max  Where\n",
      "Phi (damping)    103   0.8311   0.1351    0.4419   0.7702   0.8807   0.9255    0.9908      1\n",
      "   Loss value   4004 399.2371 278.6959 -350.4018 168.8309 320.0718 601.3232 1398.6604    474\n",
      "\n",
      "ADAM ETS Two:\n",
      "------------------------------------------------------------\n",
      "    Parameter  Count     Mean      Std       Min      Q25   Median      Q75       Max  Where\n",
      "Phi (damping)    103   0.8429   0.1360    0.4035   0.7900   0.8878   0.9368    1.0000      1\n",
      "   Loss value   4004 399.5156 278.9635 -350.4289 168.6286 320.2178 601.6846 1461.7421   3105\n",
      "\n",
      "ES Back:\n",
      "------------------------------------------------------------\n",
      "    Parameter  Count     Mean      Std       Min      Q25   Median      Q75       Max  Where\n",
      "Phi (damping)     45   0.8341   0.2001    0.2613   0.8061   0.9093   0.9824    1.0000      1\n",
      "   Loss value   4004 399.2179 279.6691 -349.8995 168.9481 320.9608 600.7808 1401.7279    474\n",
      "\n",
      "ES Opt:\n",
      "------------------------------------------------------------\n",
      "    Parameter  Count     Mean      Std       Min      Q25   Median      Q75       Max  Where\n",
      "Phi (damping)     93   0.8467   0.1231    0.4141   0.8138   0.8861   0.9347    0.9908      0\n",
      "   Loss value   4004 399.4121 278.8953 -350.1312 169.2321 320.3002 601.2995 1399.4928    474\n",
      "\n",
      "ES Two:\n",
      "------------------------------------------------------------\n",
      "    Parameter  Count                                                                                                                                                                                                                                                                                                           Mean    Std       Min      Q25   Median      Q75                                                                                                                                                                                                                                                                                                                Max  Where\n",
      "Phi (damping)     93                                                                                                                                                                                                                                                                                                         0.8612 0.1405    0.2148   0.8242   0.8978   0.9603                                                                                                                                                                                                                                                                                                             1.0000      0\n",
      "   Loss value   4004 499500499500499532528511414928621591815350573378749890580082138349561273407655268078000878694359157025640310106945737842030495927194321944216403304498642769712413144749767141691953009385898279338964300731978955666246171872421700325913556201430359981671625504642331726458400627289058794106456637440.0000    inf -345.2188 169.0672 320.0494 601.9476 1000000000000000052504760255204420248704468581108159154915854115511802457988908195786371375080447864043704443832883878176942523235360430575644792184786706982848387200926575803737830233794788090059368953234970799945081119038967640880074652742780142494579258788820056842838115669472196386865459400540160.0000    315\n"
     ]
    }
   ],
   "source": [
    "# Parameter distribution summary\n",
    "print(\"=\" * 70)\n",
    "print(\"PARAMETER DISTRIBUTION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "param_names = ['alpha', 'beta', 'gamma', 'phi', 'loss_values']\n",
    "param_labels = ['Alpha (level)', 'Beta (trend)', 'Gamma (seasonal)', 'Phi (damping)', 'Loss value']\n",
    "\n",
    "for method in methods_names:\n",
    "    print(f\"\\n{method}:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    summary_data = []\n",
    "    for param, label in zip(param_names, param_labels):\n",
    "        values = param_results[method][param]\n",
    "        valid = values[~np.isnan(values)]\n",
    "        if len(valid) > 0:\n",
    "            summary_data.append({\n",
    "                'Parameter': label,\n",
    "                'Count': len(valid),\n",
    "                'Mean': np.mean(valid),\n",
    "                'Std': np.std(valid),\n",
    "                'Min': np.min(valid),\n",
    "                'Q25': np.percentile(valid, 25),\n",
    "                'Median': np.median(valid),\n",
    "                'Q75': np.percentile(valid, 75),\n",
    "                'Max': np.max(valid),\n",
    "                'Where': np.argmax(values)\n",
    "            })\n",
    "    \n",
    "    if summary_data:\n",
    "        df = pd.DataFrame(summary_data)\n",
    "        print(df.to_string(index=False, float_format=lambda x: f'{x:.4f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421g1uahfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Easy access to individual values from the dictionary\n",
    "print(\"=\" * 70)\n",
    "print(\"EXAMPLE: ACCESSING INDIVIDUAL VALUES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get all alpha values for ADAM ETS Back method\n",
    "method = \"ADAM ETS Back\"\n",
    "print(f\"\\n1. All alpha values for {method}:\")\n",
    "print(f\"   param_results['{method}']['alpha'][:10] = {param_results[method]['alpha'][:10]}\")\n",
    "\n",
    "# Get model types for specific series indices\n",
    "print(f\"\\n2. Model types for first 5 series ({method}):\")\n",
    "for i in range(5):\n",
    "    print(f\"   Series {i}: {param_results[method]['model_types'][i]}\")\n",
    "\n",
    "# Filter by model type\n",
    "print(f\"\\n3. Alpha values for models with trend (containing 'A' or 'M' in position 2):\")\n",
    "model_types = param_results[method]['model_types']\n",
    "alpha_vals = param_results[method]['alpha']\n",
    "trend_mask = [m is not None and len(m) >= 2 and m[1] in ['A', 'M'] for m in model_types]\n",
    "alpha_with_trend = alpha_vals[trend_mask]\n",
    "print(f\"   Count: {len(alpha_with_trend)}, Mean: {np.nanmean(alpha_with_trend):.4f}\")\n",
    "\n",
    "# Compare parameters across methods\n",
    "print(f\"\\n4. Mean alpha across all methods:\")\n",
    "for method in methods_names:\n",
    "    mean_alpha = np.nanmean(param_results[method]['alpha'])\n",
    "    print(f\"   {method}: {mean_alpha:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gkdgofs32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary structure reference\n",
    "print(\"=\" * 70)\n",
    "print(\"PARAM_RESULTS DICTIONARY STRUCTURE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "param_results = {\n",
    "    'ADAM ETS Back': {\n",
    "        'model_types': [...],      # list[str]: Model types (e.g., 'AAN', 'MAdM', 'ANN')\n",
    "        'loss_values': np.array,   # float: Loss function values (CF_value)\n",
    "        'alpha': np.array,         # float: Level smoothing parameter\n",
    "        'beta': np.array,          # float: Trend smoothing parameter (NaN if no trend)\n",
    "        'gamma': np.array,         # float: Seasonal smoothing parameter (NaN if no season)\n",
    "        'phi': np.array,           # float: Dampening parameter (1.0 if not damped)\n",
    "        'errors': [...],           # list[str|None]: Error messages (None if success)\n",
    "    },\n",
    "    'ADAM ETS Opt': { ... },\n",
    "    'ADAM ETS Two': { ... },\n",
    "    'ES Back': { ... },\n",
    "    'ES Opt': { ... },\n",
    "    'ES Two': { ... },\n",
    "}\n",
    "\n",
    "Each array has length = number of datasets (4004 for M1+M3).\n",
    "Access patterns:\n",
    "  - Single value:  param_results['ADAM ETS Back']['alpha'][0]\n",
    "  - All values:    param_results['ADAM ETS Back']['alpha']\n",
    "  - By condition:  param_results['ADAM ETS Back']['alpha'][mask]\n",
    "\"\"\")\n",
    "\n",
    "# Show actual structure\n",
    "print(\"\\nActual keys in param_results:\")\n",
    "print(f\"  Methods: {list(param_results.keys())}\")\n",
    "print(f\"  Per-method keys: {list(param_results[methods_names[0]].keys())}\")\n",
    "print(f\"  Array lengths: {len(param_results[methods_names[0]]['alpha'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (smooth)",
   "language": "python",
   "name": "smooth"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
