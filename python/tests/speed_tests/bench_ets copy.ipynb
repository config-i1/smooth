{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c3a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils_benchmark import (\n",
    "    compute_all_metrics,\n",
    "    get_seasonality,\n",
    "    list_available_datasets,\n",
    "    load_dataset,\n",
    "    print_available_datasets,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from smooth.adam_general.core.adam import ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aecca808",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DATA_DIR = \"/home/filtheo/smooth/python/tests/speed_tests/benchmark_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4b0aa99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m1_monthly',\n",
       " 'm1_quarterly',\n",
       " 'm1_yearly',\n",
       " 'm3_monthly',\n",
       " 'm3_other',\n",
       " 'm3_quarterly',\n",
       " 'm3_yearly',\n",
       " 'tourism_monthly',\n",
       " 'tourism_quarterly',\n",
       " 'tourism_yearly']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_available_datasets(data_dir=None):\n",
    "    \"\"\"List all available datasets in the data directory.\"\"\"\n",
    "    data_dir = Path(data_dir) if data_dir else DEFAULT_DATA_DIR\n",
    "\n",
    "    if not data_dir.exists():\n",
    "        return []\n",
    "\n",
    "    datasets = []\n",
    "    for path in data_dir.iterdir():\n",
    "        if path.is_dir() and (path / \"metadata.csv\").exists():\n",
    "            datasets.append(path.name)\n",
    "\n",
    "    return sorted(datasets)\n",
    "\n",
    "list_available_datasets(DEFAULT_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc14b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_datetime_index_series(dataset_path, \n",
    "                                   series, h, \n",
    "                                   train_start_date='2023-01-01'):\n",
    "        \"\"\"\n",
    "        Loads train and test dataframes for a series, assigning a monthly datetime index starting at train_start_date.\n",
    "\n",
    "        Args:\n",
    "            dataset_path (str): Path to dataset directory.\n",
    "            series (str): Series ID.\n",
    "            h (int): Forecast horizon (length of test set).\n",
    "            train_start_date (str): Date string for first train index (default '2023-01-01').\n",
    "\n",
    "        Returns:\n",
    "            tuple (train_df, test_df)\n",
    "                train_df: Pandas DataFrame with datetime index.\n",
    "                test_df: Pandas DataFrame with datetime index.\n",
    "        \"\"\"\n",
    "        train_path = dataset_path + \"/\" + series + \"_train.csv\"\n",
    "        test_path = dataset_path + \"/\" + series + \"_test.csv\"\n",
    "\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        total_length = len(train_df)\n",
    "        # As we have no real date info, just generate a fixed date range starting at Jan 2000\n",
    "        dates = pd.date_range(start=train_start_date, periods=total_length, freq='M')\n",
    "        train_df['t'] = dates\n",
    "        end_date = train_df['t'].iloc[-1]\n",
    "        train_df.set_index('t', inplace=True)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        # Use DateOffset for months to advance to first test period\n",
    "        dates = pd.date_range(start=end_date + pd.DateOffset(months=1), periods=h, freq='M')\n",
    "        test_df['t'] = dates\n",
    "        test_df.set_index('t', inplace=True)\n",
    "        return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655e0b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'm1_monthly'\n",
    "dataset_path = DEFAULT_DATA_DIR + \"/\" + dataset\n",
    "\n",
    "\n",
    "metadata = pd.read_csv(dataset_path + \"/metadata.csv\")\n",
    "series_ids = metadata['series_id'].tolist()\n",
    "h = metadata['horizon'].unique()[0]\n",
    "freq = metadata['frequency'].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3c603a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series:  series_0001\n",
      "Time elapsed: 6.00 seconds\n",
      "Model estimated using ADAM() function: ETS(MMN)\n",
      "With optimal initialisation\n",
      "Distribution assumed in the model: Gamma\n",
      "Loss function type: likelihood; Loss function value: 595.9333\n",
      "Persistence vector g:\n",
      " alpha   beta\n",
      "0.0004 0.0002\n",
      "Sample size: 42\n",
      "Number of estimated parameters: 5\n",
      "Number of degrees of freedom: 37\n",
      "Information criteria:\n",
      "      AIC      AICc       BIC      BICc\n",
      "1201.8666 1203.5332 1210.5549 1213.6696\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# For every series\n",
    "for series in series_ids:\n",
    "    # Load and prepare series\n",
    "    train_df, test_df = load_and_datetime_index_series(dataset_path, series, h)\n",
    "\n",
    "    # define model \n",
    "    model_optimal = ADAM(model='ZZZ', lags=[freq], initial='optimal')\n",
    "    model_optimal.fit(train_df)\n",
    "    forecast_result = model_optimal.predict(h=h)\n",
    "    forecast_result.index = test_df.index\n",
    "    forecast_result['True'] = test_df['y']\n",
    "    forecast_result['series_id'] = series\n",
    "    print(\"Series: \", series)\n",
    "    #print('--'*30)\n",
    "    print(model_optimal)\n",
    "    print('-'*100)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84f9d2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb5462aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.08 seconds\n",
      "Model estimated using ADAM() function: ETS(MMN)\n",
      "With optimal initialisation\n",
      "Distribution assumed in the model: Gamma\n",
      "Loss function type: likelihood; Loss function value: 595.9333\n",
      "Persistence vector g:\n",
      " alpha   beta\n",
      "0.0004 0.0002\n",
      "Sample size: 42\n",
      "Number of estimated parameters: 5\n",
      "Number of degrees of freedom: 37\n",
      "Information criteria:\n",
      "      AIC      AICc       BIC      BICc\n",
      "1201.8666 1203.5332 1210.5549 1213.6696\n"
     ]
    }
   ],
   "source": [
    "model_optimal = ADAM(model='MMN', lags=[freq], initial='optimal')\n",
    "model_optimal.fit(train_df)\n",
    "print(model_optimal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
