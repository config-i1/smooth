% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/smoothCombine.R
\name{smoothCombine}
\alias{smoothCombine}
\title{Combination of forecasts of state space models}
\usage{
smoothCombine(y, models = NULL, initial = c("backcasting", "optimal",
  "two-stage", "complete"), ic = c("AICc", "AIC", "BIC", "BICc"),
  loss = c("MSE", "MAE", "HAM", "MSEh", "TMSE", "GTMSE", "MSCE"), h = 10,
  holdout = FALSE, cumulative = FALSE, interval = c("none", "prediction",
  "confidence", "simulated", "approximate", "semiparametric", "nonparametric",
  "empirical", "complete"), level = 0.95, bins = 200,
  intervalCombine = c("quantile", "probability"), bounds = c("usual",
  "admissible", "none"), silent = TRUE, xreg = NULL,
  regressors = c("use", "select"), initialX = NULL, ...)
}
\arguments{
\item{y}{Vector or ts object, containing data needed to be forecasted.}

\item{models}{List of the estimated smooth models to use in the
combination. If \code{NULL}, then all the models are estimated
in the function.}

\item{initial}{Can be \code{"optimal"}, meaning that the initial
states are optimised, or \code{"backcasting"}, meaning that the
initials are produced using backcasting procedure.}

\item{ic}{The information criterion used in the model selection procedure.}

\item{loss}{The type of Loss Function used in optimization. \code{loss} can
be: \code{likelihood} (assuming Normal distribution of error term),
\code{MSE} (Mean Squared Error), \code{MAE} (Mean Absolute Error),
\code{HAM} (Half Absolute Moment), \code{TMSE} - Trace Mean Squared Error,
\code{GTMSE} - Geometric Trace Mean Squared Error, \code{MSEh} - optimisation
using only h-steps ahead error, \code{MSCE} - Mean Squared Cumulative Error.
If \code{loss!="MSE"}, then likelihood and model selection is done based
on equivalent \code{MSE}. Model selection in this cases becomes not optimal.

There are also available analytical approximations for multistep functions:
\code{aMSEh}, \code{aTMSE} and \code{aGTMSE}. These can be useful in cases
of small samples.

Finally, just for fun the absolute and half analogues of multistep estimators
are available: \code{MAEh}, \code{TMAE}, \code{GTMAE}, \code{MACE}, \code{TMAE},
\code{HAMh}, \code{THAM}, \code{GTHAM}, \code{CHAM}.}

\item{h}{Length of forecasting horizon.}

\item{holdout}{If \code{TRUE}, holdout sample of size \code{h} is taken from
the end of the data.}

\item{cumulative}{If \code{TRUE}, then the cumulative forecast and prediction
interval are produced instead of the normal ones. This is useful for
inventory control systems.}

\item{interval}{Type of interval to construct. This can be:

\itemize{
\item \code{"none"}, aka \code{"n"} - do not produce prediction
interval.
\item \code{"parametric"}, \code{"p"} - use state-space structure of ETS. In
case of mixed models this is done using simulations, which may take longer
time than for the pure additive and pure multiplicative models. This type
of interval relies on unbiased estimate of in-sample error variance, which
divides the sume of squared errors by T-k rather than just T.
\item \code{"likelihood"}, \code{"l"} - these are the same as \code{"p"}, but
relies on the biased estimate of variance from the likelihood (division by
T, not by T-k).
\item \code{"semiparametric"}, \code{"sp"} - interval based on covariance
matrix of 1 to h steps ahead errors and assumption of normal / log-normal
distribution (depending on error type).
\item \code{"nonparametric"}, \code{"np"} - interval based on values from a
quantile regression on error matrix (see Taylor and Bunn, 1999). The model
used in this process is e[j] = a j^b, where j=1,..,h.
}
The parameter also accepts \code{TRUE} and \code{FALSE}. The former means that
parametric interval are constructed, while the latter is equivalent to
\code{none}.
If the forecasts of the models were combined, then the interval are combined
quantile-wise (Lichtendahl et al., 2013).}

\item{level}{Confidence level. Defines width of prediction interval.}

\item{bins}{The number of bins for the prediction interval.
The lower value means faster work of the function, but less
precise estimates of the quantiles. This needs to be an even
number.}

\item{intervalCombine}{How to average the prediction interval:
quantile-wise (\code{"quantile"}) or probability-wise
(\code{"probability"}).}

\item{bounds}{What type of bounds to use in the model estimation. The first
letter can be used instead of the whole word. \code{"usual"} implies restrictions on
the smoothing parameter, guaranteeing that the exponential smoothing behaves
as an averaging model. \code{"admissible"} guarantee that the model is stable.}

\item{silent}{accepts \code{TRUE} and \code{FALSE}. If FALSE, the function
will print its progress and produce a plot at the end.}

\item{xreg}{The vector (either numeric or time series) or the matrix (or
data.frame) of exogenous variables that should be included in the model. If
matrix included than columns should contain variables and rows - observations.
Note that \code{xreg} should have number of observations equal either to
in-sample or to the whole series. If the number of observations in
\code{xreg} is equal to in-sample, then values for the holdout sample are
produced using \link[smooth]{es} function.}

\item{regressors}{The variable defines what to do with the provided xreg:
\code{"use"} means that all of the data should be used, while
\code{"select"} means that a selection using \code{ic} should be done.}

\item{initialX}{The vector of initial parameters for exogenous variables.
Ignored if \code{xreg} is NULL.}

\item{...}{This currently determines nothing.

\itemize{
\item \code{timeElapsed} - time elapsed for the construction of the model.
\item \code{initialType} - type of the initial values used.
\item \code{fitted} - fitted values of ETS.
\item \code{quantiles} - the 3D array of produced quantiles if \code{interval!="none"}
with the dimensions: (number of models) x (bins) x (h).
\item \code{forecast} - point forecast of ETS.
\item \code{lower} - lower bound of prediction interval. When \code{interval="none"}
then NA is returned.
\item \code{upper} - higher bound of prediction interval. When \code{interval="none"}
then NA is returned.
\item \code{residuals} - residuals of the estimated model.
\item \code{s2} - variance of the residuals (taking degrees of freedom into account).
\item \code{interval} - type of interval asked by user.
\item \code{level} - confidence level for interval.
\item \code{cumulative} - whether the produced forecast was cumulative or not.
\item \code{y} - original data.
\item \code{holdout} - holdout part of the original data.
\item \code{xreg} - provided vector or matrix of exogenous variables. If \code{regressors="s"},
then this value will contain only selected exogenous variables.
\item \code{ICs} - values of information criteria of the model. Includes AIC, AICc, BIC and BICc.
\item \code{accuracy} - vector of accuracy measures for the holdout sample. In
case of non-intermittent data includes: MPE, MAPE, SMAPE, MASE, sMAE,
RelMAE, sMSE and Bias coefficient (based on complex numbers). In case of
intermittent data the set of errors will be: sMSE, sPIS, sCE (scaled
cumulative error) and Bias coefficient.
}}
}
\description{
Function constructs ETS, SSARIMA, CES, GUM and SMA and combines their
forecasts using IC weights.
}
\details{
The combination of these models using information criteria weights is
possible because they are all formulated in Single Source of Error
framework. Due to the the complexity of some of the models, the
estimation process may take some time. So be patient.

The prediction interval are combined either probability-wise or
quantile-wise (Lichtendahl et al., 2013), which may take extra time,
because we need to produce all the distributions for all the models.
This can be sped up with the smaller value for bins parameter, but
the resulting interval may be imprecise.
}
\examples{

\dontrun{ourModel <- smoothCombine(BJsales,interval="p")
plot(ourModel)}

# models parameter accepts either previously estimated smoothCombine
# or a manually formed list of smooth models estimated in sample:
\dontrun{smoothCombine(BJsales,models=ourModel)}

\dontrun{models <- list(es(BJsales), sma(BJsales))
smoothCombine(BJsales,models=models)}

}
\references{
\itemize{
\item Svetunkov, I., 2023. Smooth Forecasting with the Smooth Package in R. arXiv.
\doi{10.48550/arXiv.2301.01790}
\item Snyder, R. D., 1985. Recursive Estimation of Dynamic Linear Models.
Journal of the Royal Statistical Society, Series B (Methodological) 47 (2), 272-276.
\item Hyndman, R.J., Koehler, A.B., Ord, J.K., and Snyder, R.D. (2008)
Forecasting with exponential smoothing: the state space approach,
Springer-Verlag. \doi{10.1007/978-3-540-71918-2}.
}

\itemize{
\item Kolassa, S. (2011) Combining exponential smoothing forecasts using Akaike
weights. International Journal of Forecasting, 27, pp 238 - 251.
\item Svetunkov, I., Boylan, J.E., 2023b. Staying Positive: Challenges and
 Solutions in Using Pure Multiplicative ETS Models. IMA Journal of
 Management Mathematics. p. 403-425. \doi{10.1093/imaman/dpad028}
}

\itemize{
\item Taylor, J.W. and Bunn, D.W. (1999) A Quantile Regression Approach to
Generating Prediction Intervals. Management Science, Vol 45, No 2, pp
225-237.
\item Lichtendahl Kenneth C., Jr., Grushka-Cockayne Yael, Winkler
Robert L., (2013) Is It Better to Average Probabilities or
Quantiles? Management Science 59(7):1594-1611. DOI:
\doi{10.1287/mnsc.1120.1667}
}
}
\seealso{
\code{\link[smooth]{es}, \link[smooth]{auto.ssarima},
\link[smooth]{auto.ces}, \link[smooth]{auto.gum}, \link[smooth]{sma}}
}
\author{
Ivan Svetunkov, \email{ivan@svetunkov.com}
}
\keyword{models}
\keyword{nonlinear}
\keyword{regression}
\keyword{smooth}
\keyword{ts}
\keyword{univar}
